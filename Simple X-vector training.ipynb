{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488b37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Automatically reload imported modules that are changed outside this notebook\n",
    "# More pixels in figures\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2f3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d593caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-02 03:26:09.264 I numexpr.utils: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2021-06-02 03:26:09.265 I numexpr.utils: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2021-06-02 03:26:09.265 I numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "workdir = \"/tf/datasets/x-vector\"\n",
    "\n",
    "\n",
    "#meta[\"target\"] = meta[\"target\"].apply(to_1hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8653dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 03:26:13.192 W tensorflow: From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-02 03:26:13.338 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.900, 1.100]\n",
      "2021-06-02 03:26:13.558 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-02 03:26:13.644 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-02 03:26:15.345 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-02 03:26:15.357 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-02 03:26:15.792 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-02 03:26:15.805 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "\n",
    "from lidbox.features import audio, cmvn\n",
    "import lidbox.data.steps as ds_steps\n",
    "\n",
    "\n",
    "TF_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def metadata_to_dataset_input(meta):\n",
    "    return {\n",
    "        \"id\": tf.constant(meta.id, tf.string),\n",
    "        \"path\": tf.constant(meta.path, tf.string),\n",
    "        \"target\": tf.constant(meta.target, tf.int32),\n",
    "        \"split\": tf.constant(meta.split, tf.string),\n",
    "    }\n",
    "\n",
    "def read_mp3(x):\n",
    "    s, r = audio.read_mp3(x[\"path\"])\n",
    "    out_rate = 16000\n",
    "    s = audio.resample(s, r, out_rate)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    s = audio.remove_silence(s, out_rate)\n",
    "    return dict(x, signal=s, sample_rate=out_rate)\n",
    "\n",
    "\n",
    "def random_filter(x):\n",
    "    def scipy_filter(s, N=10):\n",
    "        b = np_rng.normal(0, 1, N)\n",
    "        return scipy.signal.lfilter(b, 1.0, s).astype(np.float32), b\n",
    "    s, _ = tf.numpy_function(\n",
    "        scipy_filter,\n",
    "        [x[\"signal\"]],\n",
    "        [tf.float32, tf.float64],\n",
    "        name=\"np_random_filter\")\n",
    "    s = tf.cast(s, tf.float32)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    return dict(x, signal=s)\n",
    "\n",
    "\n",
    "def random_speed_change(ds):\n",
    "    return ds_steps.random_signal_speed_change(ds, min=0.9, max=1.1, flag=None)\n",
    "\n",
    "\n",
    "def create_signal_chunks(ds):\n",
    "    ds = ds_steps.repeat_too_short_signals(ds, 3200)\n",
    "    ds = ds_steps.create_signal_chunks(ds, 3200, 800)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def batch_extract_features(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        signals, rates = x[\"signal\"], x[\"sample_rate\"]\n",
    "        S = audio.spectrograms(signals, rates[0])\n",
    "        S = audio.linear_to_mel(S, rates[0])\n",
    "        S = tf.math.log(S + 1e-6)\n",
    "        S = cmvn(S, normalize_variance=False)\n",
    "    return dict(x, logmelspec=S)\n",
    "\n",
    "def pipeline_from_meta(data, split):\n",
    "    if split == \"train\":\n",
    "        data = data.sample(frac=1, random_state=np_rng.bit_generator)\n",
    "\n",
    "    ds = (tf.data.Dataset\n",
    "            .from_tensor_slices(metadata_to_dataset_input(data))\n",
    "            .map(read_mp3, num_parallel_calls=TF_AUTOTUNE))\n",
    "\n",
    "    if split == \"train\":\n",
    "        return (ds\n",
    "            .apply(random_speed_change)\n",
    "           #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1)\n",
    "            .map(random_filter, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch())\n",
    "    else:\n",
    "        return (ds\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch()\n",
    "            #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1))\n",
    "\n",
    "\n",
    "cachedir = os.path.join(workdir, \"cache\")\n",
    "\n",
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b25dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"x-vector\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None, 40)]        0         \n",
      "_________________________________________________________________\n",
      "channel_dropout (SpatialDrop (None, None, 40)          0         \n",
      "_________________________________________________________________\n",
      "frame1 (Conv1D)              (None, None, 512)         102912    \n",
      "_________________________________________________________________\n",
      "frame2 (Conv1D)              (None, None, 512)         786944    \n",
      "_________________________________________________________________\n",
      "frame3 (Conv1D)              (None, None, 512)         786944    \n",
      "_________________________________________________________________\n",
      "frame4 (Conv1D)              (None, None, 512)         262656    \n",
      "_________________________________________________________________\n",
      "frame5 (Conv1D)              (None, None, 1500)        769500    \n",
      "_________________________________________________________________\n",
      "stats_pooling (GlobalMeanStd (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "segment1 (Dense)             (None, 512)               1536512   \n",
      "_________________________________________________________________\n",
      "segment2 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "log_softmax (Activation)     (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,510,176\n",
      "Trainable params: 4,510,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import lidbox.models.xvector as xvector\n",
    "model_input_type = \"logmelspec\"\n",
    "\n",
    "def create_model(num_freq_bins, num_labels):\n",
    "    model = xvector.create([None, num_freq_bins], num_labels, channel_dropout_rate=0.8)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), \n",
    "        metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model(\n",
    "    num_freq_bins=20 if model_input_type == \"mfcc\" else 40,\n",
    "    num_labels=4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1406b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(cachedir, \"tensorboard\", model.name),\n",
    "        update_freq=\"epoch\",\n",
    "        write_images=True,\n",
    "        profile_batch=0,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(cachedir, \"model\", model.name),\n",
    "        monitor='val_loss',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "def as_model_input(x):\n",
    "    return x[\"logmelspec\"], x[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64990a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"preparing datasets\")\n",
    "\n",
    "train_ds = split2ds[\"train\"].map(as_model_input)\n",
    "dev_ds = split2ds[\"dev\"].map(as_model_input)\n",
    "\n",
    " \n",
    "print(\"start training\")    \n",
    "with tf.device(\"GPU\"):\n",
    "    history = model.fit(\n",
    "        train_ds.batch(32).repeat(100),\n",
    "        steps_per_epoch=2576,\n",
    "        validation_data=dev_ds.batch(32).repeat(100),\n",
    "        validation_steps=961,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        epochs=100)\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model, \"xvector.h5\", overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None, save_traces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b82ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
