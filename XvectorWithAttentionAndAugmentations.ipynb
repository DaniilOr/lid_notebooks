{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5250bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Automatically reload imported modules that are changed outside this notebook\n",
    "# More pixels in figures\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3678a334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bda2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"new_test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"new_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "633ab88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = str(meta[\"Unnamed: 0\"])\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "workdir = \"/tf/datasets/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6245efd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23088    /tf/datasets/vox/ru_dev/nbC834J-lYM__U__S0---0...\n",
       "23089    /tf/datasets/vox/ru_dev/cA2lgn3QohM__U__S13---...\n",
       "23090    /tf/datasets/vox/ru_dev/aerIrz8ClqU__U__S28---...\n",
       "23091    /tf/datasets/vox/ru_dev/hGiz9AhU1dM__U__S0---0...\n",
       "23092    /tf/datasets/vox/ru_dev/HmAsKokkGyA__U__S10---...\n",
       "                               ...                        \n",
       "29020    /tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...\n",
       "29021    /tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...\n",
       "29022    /tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...\n",
       "29023    /tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...\n",
       "29024    /tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...\n",
       "Name: path, Length: 5937, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "459fe8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15966    /tf/datasets/vox/kz_dev/4QuKKCY5mAo__U__S151--...\n",
       "15967    /tf/datasets/vox/kz_dev/YNTYeSoy0HM__U__S285--...\n",
       "15968    /tf/datasets/vox/kz_dev/Gu-TfzMwS6g__U__S271--...\n",
       "15969    /tf/datasets/vox/kz_dev/ASsJmutpNjg__U__S19---...\n",
       "15970    /tf/datasets/vox/kz_dev/O0YlWuOb-YQ__U__S16---...\n",
       "                               ...                        \n",
       "23083    /tf/datasets/vox/kz_dev/23UJ403sOxA__U__S128--...\n",
       "23084    /tf/datasets/vox/kz_dev/c2VaP6HXWS0__U__S41---...\n",
       "23085    /tf/datasets/vox/kz_dev/xg8wrC8Gao4__U__S119--...\n",
       "23086    /tf/datasets/vox/kz_dev/HIPlXLT3aYw__U__S149--...\n",
       "23087    /tf/datasets/vox/kz_dev/BoTd0MzNHD0__U__S190--...\n",
       "Name: path, Length: 7122, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43c81085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10106    /tf/datasets/vox/en_dev/Jjwf054bhTU__U__S0---0...\n",
       "10107    /tf/datasets/vox/en_dev/6TEi0nJP5BE__U__S18---...\n",
       "10108    /tf/datasets/vox/en_dev/Zq4wKUsd0ZM__U__S10---...\n",
       "10109    /tf/datasets/vox/en_dev/8HzZXIchBhQ__U__S27---...\n",
       "10110    /tf/datasets/vox/en_dev/-J43Gvlztc8__U__S37---...\n",
       "                               ...                        \n",
       "15961    /tf/datasets/vox/en_dev/SHU3RJ03QlM__U__S1---0...\n",
       "15962    /tf/datasets/vox/en_dev/4wFO1Qqi3nQ__U__S0---0...\n",
       "15963    /tf/datasets/vox/en_dev/4zWSmjij-hs__U__S54---...\n",
       "15964    /tf/datasets/vox/en_dev/bi8wo64I57U__U__S0---0...\n",
       "15965    /tf/datasets/vox/en_dev/pqAQ4JkeOZI__U__S2---0...\n",
       "Name: path, Length: 5860, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b44497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000    /tf/datasets/vox/ru_test/jzh4S0PuCQo__U__S0---...\n",
       "10001    /tf/datasets/vox/ru_test/PlqiRe7CEOY__U__S141-...\n",
       "10002    /tf/datasets/vox/ru_test/6Siy_zm4gbc__U__S2---...\n",
       "10003    /tf/datasets/vox/ru_test/w4DmYzuKSU0__U__S1---...\n",
       "10004    /tf/datasets/vox/ru_test/yzy9Ps_6pMg__U__S0---...\n",
       "                               ...                        \n",
       "22102    /tf/datasets/vox/ru_test/oCp0C9NF_mA__U__S270-...\n",
       "22103    /tf/datasets/vox/ru_test/6G25joynMLI__U__S0---...\n",
       "22104    /tf/datasets/vox/ru_test/CKSJWnzoAPM__U__S2---...\n",
       "22105    /tf/datasets/vox/ru_test/5dLGBKvH_gQ__U__S1---...\n",
       "22106    /tf/datasets/vox/ru_test/pVLlwB6X-Ik__U__S0---...\n",
       "Name: path, Length: 12107, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee0c5c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22107    /tf/datasets/vox/kz_test/UjaSXBSJd3M__U__S53--...\n",
       "22108    /tf/datasets/vox/kz_test/SZNVqf0AygU__U__S123-...\n",
       "22109    /tf/datasets/vox/kz_test/1qwFgAt116E__U__S16--...\n",
       "22110    /tf/datasets/vox/kz_test/KYCkqdclYaQ__U__S32--...\n",
       "22111    /tf/datasets/vox/kz_test/g7NH6n9mcMo__U__S296-...\n",
       "                               ...                        \n",
       "36048    /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...\n",
       "36049    /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...\n",
       "36050    /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...\n",
       "36051    /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...\n",
       "36052    /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...\n",
       "Name: path, Length: 13946, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3016ba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...\n",
       "1       /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...\n",
       "2       /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...\n",
       "3       /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...\n",
       "4       /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...\n",
       "                              ...                        \n",
       "9995    /tf/datasets/vox/en_test/KLiy94kfZI4__U__S133-...\n",
       "9996    /tf/datasets/vox/en_test/YTlliEr5LOA__U__S113-...\n",
       "9997    /tf/datasets/vox/en_test/bSs0gNq6Kkc__U__S0---...\n",
       "9998    /tf/datasets/vox/en_test/Da7c-BY6MDA__U__S2---...\n",
       "9999    /tf/datasets/vox/en_test/VWvPndMo1F8__U__S24--...\n",
       "Name: path, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "132e028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66db193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a91046cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af707a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20015623.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/uk/clips/common_voice_uk_23554602.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>uk</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_20416266.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>tr</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_20263173.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/es/clips/common_voice_es_20283066.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51137 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test       2   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test       2   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test       2   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test       2   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     uk  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     tr  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it  test       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     es  test       3   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "\n",
       "[51137 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "afa6a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ff679f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/datasets/augmentedXvector/'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workdir = \"/tf/datasets/augmentedXvector/\"\n",
    "workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3de05d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---0107.830-0127.780.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---0236.830-0241.550.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---0466.720-0470.860.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110---0669.320-0675.220.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---0302.770-0318.540.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test     2.0   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test     2.0   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...     kz  test     0.0   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...     kz  test     0.0   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...  \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...  \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...  \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...  \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...  \n",
       "\n",
       "[36053 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"id\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "664f1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:05.895 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.900, 1.100]\n",
      "2021-06-13 07:01:06.030 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-13 07:01:06.043 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.439 W tensorflow: Unresolved object in checkpoint: (root).layer-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.440 W tensorflow: Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.441 W tensorflow: Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.441 W tensorflow: Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.442 W tensorflow: Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.442 W tensorflow: Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.443 W tensorflow: A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.448 W tensorflow: Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.449 W tensorflow: Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.450 W tensorflow: Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.450 W tensorflow: Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.451 W tensorflow: Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.451 W tensorflow: A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-13 07:01:06.697 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-13 07:01:06.710 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-13 07:01:07.093 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-13 07:01:07.105 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-13 07:01:07.440 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-13 07:01:07.453 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "\n",
    "from lidbox.features import audio, cmvn\n",
    "import lidbox.data.steps as ds_steps\n",
    "\n",
    "\n",
    "TF_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def metadata_to_dataset_input(meta):\n",
    "    return {\n",
    "        \"id\": tf.constant(meta.id, tf.string),\n",
    "        \"path\": tf.constant(meta.path, tf.string),\n",
    "        \"target\": tf.constant(meta.target, tf.int32),\n",
    "        \"split\": tf.constant(meta.split, tf.string),\n",
    "    }\n",
    "\n",
    "def read_mp3(x):\n",
    "    s, r = audio.read_mp3(x[\"path\"])\n",
    "    out_rate = 16000\n",
    "    s = audio.resample(s, r, out_rate)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    s = audio.remove_silence(s, out_rate)\n",
    "    return dict(x, signal=s, sample_rate=out_rate)\n",
    "\n",
    "\n",
    "def random_filter(x):\n",
    "    def scipy_filter(s, N=10):\n",
    "        b = np_rng.normal(0, 1, N)\n",
    "        return scipy.signal.lfilter(b, 1.0, s).astype(np.float32), b\n",
    "    s, _ = tf.numpy_function(\n",
    "        scipy_filter,\n",
    "        [x[\"signal\"]],\n",
    "        [tf.float32, tf.float64],\n",
    "        name=\"np_random_filter\")\n",
    "    s = tf.cast(s, tf.float32)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    return dict(x, signal=s)\n",
    "\n",
    "\n",
    "def random_speed_change(ds):\n",
    "    return ds_steps.random_signal_speed_change(ds, min=0.9, max=1.1, flag=None)\n",
    "\n",
    "\n",
    "def create_signal_chunks(ds):\n",
    "    ds = ds_steps.repeat_too_short_signals(ds, 3200)\n",
    "    ds = ds_steps.create_signal_chunks(ds, 3200, 800)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def batch_extract_features(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        signals, rates = x[\"signal\"], x[\"sample_rate\"]\n",
    "        S = audio.spectrograms(signals, rates[0])\n",
    "        S = audio.linear_to_mel(S, rates[0])\n",
    "        S = tf.math.log(S + 1e-6)\n",
    "        S = cmvn(S, normalize_variance=False)\n",
    "    return dict(x, logmelspec=S)\n",
    "\n",
    "def pipeline_from_meta(data, split):\n",
    "    if split == \"train\":\n",
    "        data = data.sample(frac=1, random_state=np_rng.bit_generator)\n",
    "\n",
    "    ds = (tf.data.Dataset\n",
    "            .from_tensor_slices(metadata_to_dataset_input(data))\n",
    "            .map(read_mp3, num_parallel_calls=TF_AUTOTUNE))\n",
    "\n",
    "    if split == \"train\":\n",
    "        return (ds\n",
    "            .apply(random_speed_change)\n",
    "           #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1)\n",
    "            .map(random_filter, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch())\n",
    "    else:\n",
    "        return (ds\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(1)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch()\n",
    "            #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1))\n",
    "\n",
    "\n",
    "cachedir = os.path.join(workdir, \"cache\")\n",
    "\n",
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c801c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Layer,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def frame_layer(filters, kernel_size, strides, padding=\"causal\", activation=\"relu\", name=\"frame\"):\n",
    "    return Conv1D(filters, kernel_size, strides, padding=padding, activation=activation, name=name)\n",
    "\n",
    "\n",
    "def segment_layer(units, activation=\"relu\", name=\"segment\"):\n",
    "    return Dense(units, activation=activation, name=name)\n",
    "class GlobalMeanStddevPooling1D(Layer):\n",
    "    \"\"\"\n",
    "    Compute arithmetic mean and standard deviation of the inputs along the time steps dimension,\n",
    "    then output the concatenation of the computed stats.\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        means = tf.math.reduce_mean(inputs, axis=TIME_AXIS, keepdims=True)\n",
    "        variances = tf.math.reduce_mean(tf.math.square(inputs - means), axis=TIME_AXIS)\n",
    "        means = tf.squeeze(means, TIME_AXIS)\n",
    "        stddevs = tf.math.sqrt(tf.clip_by_value(variances, STDDEV_SQRT_MIN_CLIP, variances.dtype.max))\n",
    "        return tf.concat((means, stddevs), axis=TIME_AXIS)\n",
    "\n",
    "def as_embedding_extractor(m):\n",
    "    l = m.get_layer(name=\"segment1\")\n",
    "    l.activation = None\n",
    "    return Model(inputs=m.inputs, outputs=l.output)\n",
    "\n",
    "def frequency_attention(H, d_a=64, d_f=16):\n",
    "    assert not H.shape[2] % d_f, \"amount of frequency channels ({}) must be evenly divisible by the amount of frequency attention bins (d_f={})\".format(H.shape[2], d_f)\n",
    "    # Note, we assume that H.shape = (batch_size, T, d_h), but the paper assumes the timesteps come last\n",
    "    x = Dense(d_a, activation=\"relu\", use_bias=False, name=\"Wf_1\")(H)\n",
    "    F_A = Dense(d_f, activation=\"softmax\", use_bias=False, name=\"Wf_2\")(x)\n",
    "    # Apply frequency attention on d_f bins\n",
    "    F_A = Reshape((F_A.shape[1] or -1, F_A.shape[2], 1), name=\"expand_bin_weight_dim\")(F_A)\n",
    "    H_bins = Reshape((H.shape[1] or -1, d_f, H.shape[2] // d_f), name=\"partition_freq_bins\")(H)\n",
    "    H_bins = Multiply(name=\"freq_attention\")([F_A, H_bins])\n",
    "    # Merge weighted frequency bins\n",
    "    H_weighted = Reshape((H.shape[1] or -1, H.shape[2]), name=\"merge_weighted_bins\")(H_bins)\n",
    "    return H_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b26bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    GaussianNoise,\n",
    "    Input,\n",
    "    Layer,\n",
    "    LSTM,\n",
    "    Multiply,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming spectral features (Batch, Time, Channels), where freq. channels are always last\n",
    "TIME_AXIS = 1\n",
    "STDDEV_SQRT_MIN_CLIP = 1e-10\n",
    "\n",
    "def create(input_shape, num_outputs, output_activation=\"log_softmax\", freq_attention_bins=60):\n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "    x = SpatialDropout1D(0.7, name=\"channel_dropout\")(inputs)\n",
    "    x = frame_layer(512, 5, 1, name=\"frame1\")(x)\n",
    "    x = frame_layer(512, 3, 2, name=\"frame2\")(x)\n",
    "    x = frame_layer(512, 3, 3, name=\"frame3\")(x)\n",
    "    x = frame_layer(512, 1, 1, name=\"frame4\")(x)\n",
    "    x = frame_layer(1500, 1, 1, name=\"frame5\")(x)\n",
    "\n",
    "    x = frequency_attention(x, d_f=freq_attention_bins)\n",
    "\n",
    "    x = GlobalMeanStddevPooling1D(name=\"stats_pooling\")(x)\n",
    "\n",
    "    x = segment_layer(512, name=\"segment1\")(x)\n",
    "    x = segment_layer(512, name=\"segment2\")(x)\n",
    "\n",
    "    outputs = Dense(num_outputs, name=\"output\", activation=None)(x)\n",
    "    if output_activation:\n",
    "        outputs = Activation(getattr(tf.nn, output_activation), name=str(output_activation))(outputs)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"x-vector-frequency-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852a7826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"x-vector-frequency-attention\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 20)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "channel_dropout (SpatialDropout (None, None, 20)     0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frame1 (Conv1D)                 (None, None, 512)    51712       channel_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "frame2 (Conv1D)                 (None, None, 512)    786944      frame1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame3 (Conv1D)                 (None, None, 512)    786944      frame2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame4 (Conv1D)                 (None, None, 512)    262656      frame3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame5 (Conv1D)                 (None, None, 1500)   769500      frame4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_1 (Dense)                    (None, None, 64)     96000       frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_2 (Dense)                    (None, None, 60)     3840        Wf_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "expand_bin_weight_dim (Reshape) (None, None, 60, 1)  0           Wf_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "partition_freq_bins (Reshape)   (None, None, 60, 25) 0           frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "freq_attention (Multiply)       (None, None, 60, 25) 0           expand_bin_weight_dim[0][0]      \n",
      "                                                                 partition_freq_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_weighted_bins (Reshape)   (None, None, 1500)   0           freq_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stats_pooling (GlobalMeanStddev (None, 3000)         0           merge_weighted_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "segment1 (Dense)                (None, 512)          1536512     stats_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "segment2 (Dense)                (None, 512)          262656      segment1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 4)            2052        segment2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "log_softmax (Activation)        (None, 4)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,558,816\n",
      "Trainable params: 4,558,816\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_model(num_freq_bins=20, num_labels=len(np.unique(meta.target))):\n",
    "    m = create(\n",
    "        input_shape=[None, num_freq_bins],\n",
    "        num_outputs=4)\n",
    "    m.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "    return m\n",
    "\n",
    "with tf.device(\"GPU\"):\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "   \n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(cachedir, \"tensorboard\", model.name),\n",
    "        update_freq=\"epoch\",\n",
    "        write_images=True,\n",
    "        profile_batch=0,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(cachedir, \"model\", model.name),\n",
    "        monitor='val_loss',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "def as_model_input(x):\n",
    "    return x[\"logmelspec\"], x[\"target\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "074a6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = \"/tf/datasets/augmentedXvector/cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc2eead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/datasets/augmentedXvector/cache/model/x-vector-frequency-attention\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from lidbox.util import predict_with_model, classification_report\n",
    "from lidbox.visualize import draw_confusion_matrix\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    model = create_model()\n",
    "    print(os.path.join(cachedir, \"model\", model.name))\n",
    "    model.load_weights(os.path.join(cachedir, \"model\", model.name))\n",
    "    return model\n",
    "\n",
    "\n",
    "def display_classification_report(report):\n",
    "    for m in (\"avg_detection_cost\", \"avg_equal_error_rate\", \"accuracy\"):\n",
    "        print(\"{}: {:.3f}\".format(m, report[m]))\n",
    "\n",
    "    lang_metrics = pd.DataFrame.from_dict(\n",
    "        {k: v for k, v in report.items() if k in lang2target})\n",
    "    lang_metrics[\"mean\"] = lang_metrics.mean(axis=1)\n",
    "    display(lang_metrics.T)\n",
    "\n",
    "    fig, ax = draw_confusion_matrix(report[\"confusion_matrix\"], lang2target)\n",
    "\n",
    "model = load_trained_model()\n",
    "\n",
    "def predict_with_ap_loss(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        # Generate language vector for input spectra\n",
    "        language_vector = model(x[\"input\"], training=False)\n",
    "        print(language_vector)\n",
    "        # Predict languages by computing distances to reference directions\n",
    "        return x[\"id\"], model.loss.predict(language_vector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8606b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictions_to_dataframe(ids, predictions):\n",
    "    return (pd.DataFrame.from_dict({\"id\": ids, \"prediction\": predictions})\n",
    "            #.set_index(\"id\", drop=True, verify_integrity=True)\n",
    "            #.sort_index()\n",
    "           )\n",
    "\n",
    "def predict_with_model(model, ds, predict_fn=None):\n",
    "    \"\"\"\n",
    "    Map callable model over all batches in ds, predicting values for each element at key 'input'.\n",
    "    \"\"\"\n",
    "    if predict_fn is None:\n",
    "        def predict_fn(x):\n",
    "            with tf.device(\"GPU\"):\n",
    "                return x[\"id\"], model(x[\"input\"], training=False)\n",
    "\n",
    "    ids = []\n",
    "    predictions = []\n",
    "    for id, pred in ds.map(predict_fn, num_parallel_calls=TF_AUTOTUNE).unbatch().as_numpy_iterator():\n",
    "        ids.append(id.decode(\"utf-8\"))\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return predictions_to_dataframe(ids, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac67a88e",
   "metadata": {},
   "source": [
    "## Test on vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49fca1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d493b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c845db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133---0944.430-0958.260.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123---0427.020-0444.670.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0398.760-0403.940.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1473.480-1485.720.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0125.230-0140.900.mp3</th>\n",
       "      <td>/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...</td>\n",
       "      <td>en</td>\n",
       "      <td>test</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---0107.830-0127.780.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---0236.830-0241.550.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---0466.720-0470.860.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110---0669.320-0675.220.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---0302.770-0318.540.mp3</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>kz</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "id                                                                                                      \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...  /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...  /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...   \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...  /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...   \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...  /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...   \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...  /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...  /tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25--...   \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...  /tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26--...   \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...  /tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78--...   \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...  /tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110-...   \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                                   locale split  target  \n",
       "id                                                                       \n",
       "/tf/datasets/vox/en_test/shrDRhToGpY__U__S133--...     en  test     2.0  \n",
       "/tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123--...     en  test     2.0  \n",
       "/tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---0...     en  test     2.0  \n",
       "/tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---1...     en  test     2.0  \n",
       "/tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---0...     en  test     2.0  \n",
       "...                                                   ...   ...     ...  \n",
       "/tf/datasets/vox/kz_test/rCpb0p_lyxI__U__S25---...     kz  test     0.0  \n",
       "/tf/datasets/vox/kz_test/BkLVX9wf2YI__U__S26---...     kz  test     0.0  \n",
       "/tf/datasets/vox/kz_test/RqdH-JD8TpM__U__S78---...     kz  test     0.0  \n",
       "/tf/datasets/vox/kz_test/oCjW4Jy6azE__U__S110--...     kz  test     0.0  \n",
       "/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30---...     kz  test     0.0  \n",
       "\n",
       "[36053 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88284cd",
   "metadata": {},
   "source": [
    "Ru sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b963a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = predict_with_model(\n",
    "    model=model,\n",
    "    ds=split2ds[\"test\"].map(lambda x: dict(x, input=x[\"logmelspec\"])).batch(32),\n",
    "    #predict_fn=predict_with_ap_loss\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c327583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>[-0.07002593, -5.7154145, -2.9013617, -4.6683955]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>[-1.1671677, -3.3739388, -0.5356533, -2.6705878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>[-2.5124385, -1.915247, -0.3730118, -2.4893112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>[-0.9713418, -1.0899353, -1.9481032, -1.9474114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...</td>\n",
       "      <td>[-1.0492101, -1.7267493, -2.0425928, -1.0722663]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334514</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>[-0.32531023, -3.5286946, -2.813746, -1.6693275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334515</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>[-0.17609802, -4.480584, -2.3373587, -2.9270456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334516</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>[-0.45195174, -3.5194185, -1.8153256, -1.764844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334517</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>[-0.9917979, -3.170356, -1.4174447, -1.064879]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334518</th>\n",
       "      <td>/tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...</td>\n",
       "      <td>[-0.29162645, -3.985016, -2.1736193, -2.1153152]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334519 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       id  \\\n",
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "1       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "2       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "3       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "4       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...   \n",
       "...                                                   ...   \n",
       "334514  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "334515  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "334516  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "334517  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "334518  /tf/datasets/vox/kz_test/cwyX-Vjxep4__U__S30--...   \n",
       "\n",
       "                                               prediction  \n",
       "0       [-0.07002593, -5.7154145, -2.9013617, -4.6683955]  \n",
       "1        [-1.1671677, -3.3739388, -0.5356533, -2.6705878]  \n",
       "2         [-2.5124385, -1.915247, -0.3730118, -2.4893112]  \n",
       "3        [-0.9713418, -1.0899353, -1.9481032, -1.9474114]  \n",
       "4        [-1.0492101, -1.7267493, -2.0425928, -1.0722663]  \n",
       "...                                                   ...  \n",
       "334514   [-0.32531023, -3.5286946, -2.813746, -1.6693275]  \n",
       "334515   [-0.17609802, -4.480584, -2.3373587, -2.9270456]  \n",
       "334516   [-0.45195174, -3.5194185, -1.8153256, -1.764844]  \n",
       "334517     [-0.9917979, -3.170356, -1.4174447, -1.064879]  \n",
       "334518   [-0.29162645, -3.985016, -2.1736193, -2.1153152]  \n",
       "\n",
       "[334519 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk2pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93196883",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = chunk2pred.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "142f60e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0003.940-0020.570.mp3</th>\n",
       "      <td>[-1.0297503, -3.851068, -1.5921042, -1.3939339]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0743.730-0757.100.mp3</th>\n",
       "      <td>[-1.734242, -3.4777792, -1.0620568, -1.0570086]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0650.920-0661.560.mp3</th>\n",
       "      <td>[-1.4066441, -2.2093089, -1.649218, -1.0521832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0692.790-0704.510.mp3</th>\n",
       "      <td>[-1.2719195, -2.2588575, -1.7421018, -1.2674958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0705.010-0711.610.mp3</th>\n",
       "      <td>[-1.813632, -2.107427, -1.5414699, -0.9765296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0219.180-0230.690.mp3</th>\n",
       "      <td>[-2.3263788, -1.9312198, -2.472705, -1.0607697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0230.690-0247.370.mp3</th>\n",
       "      <td>[-2.7114298, -1.2576344, -3.0530705, -1.3916095]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0247.370-0257.750.mp3</th>\n",
       "      <td>[-2.3065178, -1.8669779, -2.068025, -1.0563043]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0277.000-0287.980.mp3</th>\n",
       "      <td>[-3.0081248, -1.351705, -2.2362683, -1.1987343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---0301.200-0306.760.mp3</th>\n",
       "      <td>[-1.9379988, -1.9034048, -1.8363597, -0.61685693]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           prediction\n",
       "id                                                                                                   \n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...    [-1.0297503, -3.851068, -1.5921042, -1.3939339]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...    [-1.734242, -3.4777792, -1.0620568, -1.0570086]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...    [-1.4066441, -2.2093089, -1.649218, -1.0521832]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...   [-1.2719195, -2.2588575, -1.7421018, -1.2674958]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...     [-1.813632, -2.107427, -1.5414699, -0.9765296]\n",
       "...                                                                                               ...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...    [-2.3263788, -1.9312198, -2.472705, -1.0607697]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...   [-2.7114298, -1.2576344, -3.0530705, -1.3916095]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...    [-2.3065178, -1.8669779, -2.068025, -1.0563043]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...    [-3.0081248, -1.351705, -2.2362683, -1.1987343]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---...  [-1.9379988, -1.9034048, -1.8363597, -0.61685693]\n",
       "\n",
       "[36053 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lidbox.util import merge_chunk_predictions\n",
    "\n",
    "\n",
    "utt2pred = merge_chunk_predictions(chunk2pred)\n",
    "utt2pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9a70898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.45      0.46      0.45     13946\n",
      "          ru       0.78      0.25      0.37     12107\n",
      "          en       0.98      0.24      0.39     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33     36053\n",
      "   macro avg       0.55      0.24      0.30     36053\n",
      "weighted avg       0.71      0.33      0.41     36053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_meta = meta[meta[\"split\"]==\"test\"].join(utt2pred, how=\"outer\")\n",
    "assert not test_meta.isna().any(axis=None), \"failed to join predictions\"\n",
    "\n",
    "true_sparse = test_meta.target.to_numpy(np.int32)\n",
    "pred_dense = np.stack(test_meta.prediction.apply(np.argmax))\n",
    "\n",
    "report = classification_report(true_sparse, pred_dense, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
