{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b95c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Automatically reload imported modules that are changed outside this notebook\n",
    "# More pixels in figures\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c6604e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e25a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06443b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/tf/datasets/augmentedXvector/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eeaa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c4813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f61bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "from lidbox.features import audio, cmvn\n",
    "import lidbox.data.steps as ds_steps\n",
    "\n",
    "\n",
    "TF_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def metadata_to_dataset_input(meta):\n",
    "    return {\n",
    "        \"id\": tf.constant(meta.id, tf.string),\n",
    "        \"path\": tf.constant(meta.path, tf.string),\n",
    "        \"target\": tf.constant(meta.target, tf.int32),\n",
    "        \"split\": tf.constant(meta.split, tf.string),\n",
    "    }\n",
    "\n",
    "def read_mp3(x):\n",
    "    s, r = audio.read_mp3(x[\"path\"])\n",
    "    out_rate = 16000\n",
    "    s = audio.resample(s, r, out_rate)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    s = audio.remove_silence(s, out_rate)\n",
    "    return dict(x, signal=s, sample_rate=out_rate)\n",
    "\n",
    "\n",
    "def random_filter(x):\n",
    "    def scipy_filter(s, N=10):\n",
    "        b = np_rng.normal(0, 1, N)\n",
    "        return scipy.signal.lfilter(b, 1.0, s).astype(np.float32), b\n",
    "    s, _ = tf.numpy_function(\n",
    "        scipy_filter,\n",
    "        [x[\"signal\"]],\n",
    "        [tf.float32, tf.float64],\n",
    "        name=\"np_random_filter\")\n",
    "    s = tf.cast(s, tf.float32)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    return dict(x, signal=s)\n",
    "\n",
    "\n",
    "def random_speed_change(ds):\n",
    "    return ds_steps.random_signal_speed_change(ds, min=0.5, max=1.5, flag=None)\n",
    "\n",
    "\n",
    "def create_signal_chunks(ds):\n",
    "    ds = ds_steps.repeat_too_short_signals(ds, 3200)\n",
    "    ds = ds_steps.create_signal_chunks(ds, 3200, 800)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def batch_extract_features(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        signals, rates = x[\"signal\"], x[\"sample_rate\"]\n",
    "        S = audio.spectrograms(signals, rates[0])\n",
    "        S = audio.linear_to_mel(S, rates[0])\n",
    "        S = tf.math.log(S + 1e-6)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(S)\n",
    "        mfccs = mfccs[...,1:21]\n",
    "        S = cmvn(S, normalize_variance=False)\n",
    "        mfccs_cmvn = cmvn(mfccs)\n",
    "\n",
    "        #S = tfio.audio.freq_mask(S, param=10)\n",
    "        #S = tfio.audio.time_mask(S, param=10)\n",
    "    return dict(x, logmelspec=S, mfccs=mfccs)\n",
    "\n",
    "\n",
    "def pipeline_from_meta(data, split):\n",
    "    if split == \"train\":\n",
    "        data = data.sample(frac=1, random_state=np_rng.bit_generator)\n",
    "\n",
    "    ds = (tf.data.Dataset\n",
    "            .from_tensor_slices(metadata_to_dataset_input(data))\n",
    "            .map(read_mp3, num_parallel_calls=TF_AUTOTUNE))\n",
    "\n",
    "    if split == \"train\":\n",
    "        return (ds\n",
    "            .apply(random_speed_change)\n",
    "           #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(32)\n",
    "            .map(random_filter, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(32)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch())\n",
    "    else:\n",
    "        return (ds\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(32)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch()\n",
    "            #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1))\n",
    "\n",
    "\n",
    "cachedir = os.path.join(workdir, \"cache\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed72e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 11:18:18.170 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.500, 1.500]\n",
      "2021-06-27 11:18:18.194 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:18.206 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 11:18:18.577 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:18.590 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 11:18:18.946 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:18.959 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    }
   ],
   "source": [
    "val_data = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}\n",
    "val_data = val_data['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "651b4f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 11:18:19.549 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.500, 1.500]\n",
      "2021-06-27 11:18:19.572 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:19.584 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 11:18:19.944 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:19.957 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 11:18:20.307 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 11:18:20.320 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    }
   ],
   "source": [
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49c172e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    " \n",
    "   Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Layer,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming spectral features (Batch, Time, Channels), where freq. channels are always last\n",
    "TIME_AXIS = 1\n",
    "STDDEV_SQRT_MIN_CLIP = 1e-10\n",
    "\n",
    "\n",
    "class GlobalMeanStddevPooling1D(Layer):\n",
    "    \"\"\"\n",
    "    Compute arithmetic mean and standard deviation of the inputs along the time steps dimension,\n",
    "    then output the concatenation of the computed stats.\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        means = tf.math.reduce_mean(inputs, axis=TIME_AXIS, keepdims=True)\n",
    "        variances = tf.math.reduce_mean(tf.math.square(inputs - means), axis=TIME_AXIS)\n",
    "        means = tf.squeeze(means, TIME_AXIS)\n",
    "        stddevs = tf.math.sqrt(tf.clip_by_value(variances, STDDEV_SQRT_MIN_CLIP, variances.dtype.max))\n",
    "        return tf.concat((means, stddevs), axis=TIME_AXIS)\n",
    "\n",
    "\n",
    "def frame_layer(filters, kernel_size, strides, padding=\"causal\", activation=\"relu\", name=\"frame\"):\n",
    "    return Conv1D(filters, kernel_size, strides, padding=padding, activation=activation, name=name)\n",
    "\n",
    "\n",
    "def segment_layer(units, activation=\"relu\", name=\"segment\"):\n",
    "    return Dense(units, activation=activation, name=name)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    GaussianNoise,\n",
    "    Input,\n",
    "    Layer,\n",
    "    LSTM,\n",
    "    Multiply,\n",
    "    Reshape,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def frequency_attention(H, d_a=64, d_f=16):\n",
    "    assert not H.shape[2] % d_f, \"amount of frequency channels ({}) must be evenly divisible by the amount of frequency attention bins (d_f={})\".format(H.shape[2], d_f)\n",
    "    # Note, we assume that H.shape = (batch_size, T, d_h), but the paper assumes the timesteps come last\n",
    "    x = Dense(d_a, activation=\"relu\", use_bias=False, name=\"Wf_1\")(H)\n",
    "    F_A = Dense(d_f, activation=\"softmax\", use_bias=False, name=\"Wf_2\")(x)\n",
    "    # Apply frequency attention on d_f bins\n",
    "    F_A = Reshape((F_A.shape[1] or -1, F_A.shape[2], 1), name=\"expand_bin_weight_dim\")(F_A)\n",
    "    H_bins = Reshape((H.shape[1] or -1, d_f, H.shape[2] // d_f), name=\"partition_freq_bins\")(H)\n",
    "    H_bins = Multiply(name=\"freq_attention\")([F_A, H_bins])\n",
    "    # Merge weighted frequency bins\n",
    "    H_weighted = Reshape((H.shape[1] or -1, H.shape[2]), name=\"merge_weighted_bins\")(H_bins)\n",
    "    return H_weighted\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Input,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def create(input_shape, num_outputs, output_activation=\"log_softmax\", freq_attention_bins=60):\n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = frame_layer(512, 5, 1, name=\"frame1\")(inputs)\n",
    "    x = frame_layer(512, 3, 2, name=\"frame2\")(x)\n",
    "    x = frame_layer(512, 3, 3, name=\"frame3\")(x)\n",
    "    x = frame_layer(512, 1, 1, name=\"frame4\")(x)\n",
    "    x = frame_layer(1500, 1, 1, name=\"frame5\")(x)\n",
    "\n",
    "    x = frequency_attention(x, d_f=freq_attention_bins)\n",
    "\n",
    "    x = GlobalMeanStddevPooling1D(name=\"stats_pooling\")(x)\n",
    "\n",
    "    x = segment_layer(512, name=\"segment1\")(x)\n",
    "    x = segment_layer(512, name=\"segment2\")(x)\n",
    "\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=x, name=\"x-vector-frequency-attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "650648b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"x-vector-frequency-attention\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "frame1 (Conv1D)                 (None, None, 512)    102912      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frame2 (Conv1D)                 (None, None, 512)    786944      frame1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame3 (Conv1D)                 (None, None, 512)    786944      frame2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame4 (Conv1D)                 (None, None, 512)    262656      frame3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame5 (Conv1D)                 (None, None, 1500)   769500      frame4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_1 (Dense)                    (None, None, 64)     96000       frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_2 (Dense)                    (None, None, 60)     3840        Wf_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "expand_bin_weight_dim (Reshape) (None, None, 60, 1)  0           Wf_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "partition_freq_bins (Reshape)   (None, None, 60, 25) 0           frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "freq_attention (Multiply)       (None, None, 60, 25) 0           expand_bin_weight_dim[0][0]      \n",
      "                                                                 partition_freq_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_weighted_bins (Reshape)   (None, None, 1500)   0           freq_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stats_pooling (GlobalMeanStddev (None, 3000)         0           merge_weighted_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "segment1 (Dense)                (None, 512)          1536512     stats_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "segment2 (Dense)                (None, 512)          262656      segment1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,607,964\n",
      "Trainable params: 4,607,964\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_freq_bins=40, num_labels=len(np.unique(meta.target))):\n",
    "    m = create(\n",
    "        input_shape=[None, num_freq_bins],\n",
    "        num_outputs=num_labels)\n",
    "    \"\"\"\n",
    "    m.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "    \"\"\"\n",
    "    return m\n",
    "\n",
    "with tf.device(\"GPU\"):\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb11bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False\n",
    "x = model.layers[-1].output\n",
    "x = Dense(128, activation = \"relu\")(x)\n",
    "predictions = Dense(4, activation = \"softmax\")(x)\n",
    "clf1 = Model(inputs = model.input, outputs = predictions, name=\"clf1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "021704d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"clf1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "frame1 (Conv1D)                 (None, None, 512)    102912      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frame2 (Conv1D)                 (None, None, 512)    786944      frame1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame3 (Conv1D)                 (None, None, 512)    786944      frame2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame4 (Conv1D)                 (None, None, 512)    262656      frame3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame5 (Conv1D)                 (None, None, 1500)   769500      frame4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_1 (Dense)                    (None, None, 64)     96000       frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_2 (Dense)                    (None, None, 60)     3840        Wf_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "expand_bin_weight_dim (Reshape) (None, None, 60, 1)  0           Wf_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "partition_freq_bins (Reshape)   (None, None, 60, 25) 0           frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "freq_attention (Multiply)       (None, None, 60, 25) 0           expand_bin_weight_dim[0][0]      \n",
      "                                                                 partition_freq_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_weighted_bins (Reshape)   (None, None, 1500)   0           freq_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stats_pooling (GlobalMeanStddev (None, 3000)         0           merge_weighted_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "segment1 (Dense)                (None, 512)          1536512     stats_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "segment2 (Dense)                (None, 512)          262656      segment1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          65664       segment2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 4)            516         dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,674,144\n",
      "Trainable params: 66,180\n",
      "Non-trainable params: 4,607,964\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ab4fde6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_24\n",
      "dense_25\n"
     ]
    }
   ],
   "source": [
    "for l in clf1.layers:\n",
    "    if l.trainable:\n",
    "        print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2f58a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a777312",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2635bacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"x-vector-frequency-attention\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "frame1 (Conv1D)                 (None, None, 512)    102912      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frame2 (Conv1D)                 (None, None, 512)    786944      frame1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame3 (Conv1D)                 (None, None, 512)    786944      frame2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame4 (Conv1D)                 (None, None, 512)    262656      frame3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame5 (Conv1D)                 (None, None, 1500)   769500      frame4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_1 (Dense)                    (None, None, 64)     96000       frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_2 (Dense)                    (None, None, 60)     3840        Wf_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "expand_bin_weight_dim (Reshape) (None, None, 60, 1)  0           Wf_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "partition_freq_bins (Reshape)   (None, None, 60, 25) 0           frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "freq_attention (Multiply)       (None, None, 60, 25) 0           expand_bin_weight_dim[0][0]      \n",
      "                                                                 partition_freq_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_weighted_bins (Reshape)   (None, None, 1500)   0           freq_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stats_pooling (GlobalMeanStddev (None, 3000)         0           merge_weighted_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "segment1 (Dense)                (None, 512)          1536512     stats_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "segment2 (Dense)                (None, 512)          262656      segment1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,607,964\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,607,964\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    if l.trainable:\n",
    "        print(l)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "711e05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False\n",
    "x = model.layers[-1].output\n",
    "x = Dense(128, activation = \"relu\")(x)\n",
    "predictions = Dense(4, activation = \"softmax\")(x)\n",
    "clf2 = Model(inputs = model.input, outputs = predictions, name=\"clf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "677c84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b3c91e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_26\n",
      "dense_27\n"
     ]
    }
   ],
   "source": [
    "clf2.trainable = True\n",
    "model.trainable = False\n",
    "for l in clf2.layers:\n",
    "    if l.trainable:\n",
    "        print(l.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5542736",
   "metadata": {},
   "source": [
    "## Testing on common voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "729fd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b823c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = tf.keras.models.load_model('clf1_2/model')\n",
    "\n",
    "clf2 = tf.keras.models.load_model('clf2_2/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50651570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictions_to_dataframe(ids, predictions):\n",
    "    return (pd.DataFrame.from_dict({\"id\": ids, \"prediction\": predictions})\n",
    "            #.set_index(\"id\", drop=True, verify_integrity=True)\n",
    "            #.sort_index()\n",
    "           )\n",
    "\n",
    "def predict_with_model(model, ds, predict_fn=None):\n",
    "    \"\"\"\n",
    "    Map callable model over all batches in ds, predicting values for each element at key 'input'.\n",
    "    \"\"\"\n",
    "    if predict_fn is None:\n",
    "        def predict_fn(x):\n",
    "            with tf.device(\"GPU\"):\n",
    "                return x[\"id\"], model(x[\"input\"], training=False)\n",
    "\n",
    "    ids = []\n",
    "    predictions = []\n",
    "    for id, pred in ds.map(predict_fn, num_parallel_calls=TF_AUTOTUNE).unbatch().as_numpy_iterator():\n",
    "        ids.append(id.decode(\"utf-8\"))\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return predictions_to_dataframe(ids, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e372c9",
   "metadata": {},
   "source": [
    "### Testing CLF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb200cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = predict_with_model(\n",
    "    model=clf1,\n",
    "    ds=split2ds[\"test\"].map(lambda x: dict(x, input=x[\"logmelspec\"])).batch(32),\n",
    "    #predict_fn=predict_with_ap_loss\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb72bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = chunk2pred.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a79eb910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0003.940-0020.570.mp3</th>\n",
       "      <td>[0.74763554, 0.015166172, 0.11314385, 0.12405445]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0743.730-0757.100.mp3</th>\n",
       "      <td>[0.6527672, 0.015340386, 0.17765337, 0.15423909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0650.920-0661.560.mp3</th>\n",
       "      <td>[0.979149, 0.00094241154, 0.011158215, 0.00875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0692.790-0704.510.mp3</th>\n",
       "      <td>[0.93517745, 0.010677641, 0.023704082, 0.03044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0705.010-0711.610.mp3</th>\n",
       "      <td>[0.8223988, 0.036917165, 0.056642402, 0.08404159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0219.180-0230.690.mp3</th>\n",
       "      <td>[0.9637271, 0.005408268, 0.011009475, 0.019855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0230.690-0247.370.mp3</th>\n",
       "      <td>[0.9565367, 0.017204842, 0.008147814, 0.018110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0247.370-0257.750.mp3</th>\n",
       "      <td>[0.9306425, 0.009629078, 0.031984303, 0.027744...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0277.000-0287.980.mp3</th>\n",
       "      <td>[0.75604516, 0.043308392, 0.10529836, 0.09534811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---0301.200-0306.760.mp3</th>\n",
       "      <td>[0.062669754, 0.29940042, 0.20704284, 0.43088698]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           prediction\n",
       "id                                                                                                   \n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...  [0.74763554, 0.015166172, 0.11314385, 0.12405445]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...   [0.6527672, 0.015340386, 0.17765337, 0.15423909]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.979149, 0.00094241154, 0.011158215, 0.00875...\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.93517745, 0.010677641, 0.023704082, 0.03044...\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.8223988, 0.036917165, 0.056642402, 0.08404159]\n",
       "...                                                                                               ...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9637271, 0.005408268, 0.011009475, 0.019855...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9565367, 0.017204842, 0.008147814, 0.018110...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9306425, 0.009629078, 0.031984303, 0.027744...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.75604516, 0.043308392, 0.10529836, 0.09534811]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---...  [0.062669754, 0.29940042, 0.20704284, 0.43088698]\n",
       "\n",
       "[36053 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lidbox.util import merge_chunk_predictions\n",
    "\n",
    "\n",
    "utt2pred = merge_chunk_predictions(chunk2pred)\n",
    "utt2pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f0a0e",
   "metadata": {},
   "source": [
    "### Results of CLF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48e64404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.39      0.98      0.56     13946\n",
      "          ru       0.75      0.01      0.01     12107\n",
      "          en       0.64      0.01      0.02     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38     36053\n",
      "   macro avg       0.44      0.25      0.15     36053\n",
      "weighted avg       0.58      0.38      0.22     36053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_meta = meta[meta[\"split\"]==\"test\"].join(utt2pred, how=\"outer\")\n",
    "assert not test_meta.isna().any(axis=None), \"failed to join predictions\"\n",
    "\n",
    "true_sparse = test_meta.target.to_numpy(np.int32)\n",
    "pred_dense = np.stack(test_meta.prediction.apply(np.argmax))\n",
    "\n",
    "report = classification_report(true_sparse, pred_dense, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef2975",
   "metadata": {},
   "source": [
    "### Testing clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0efc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = predict_with_model(\n",
    "    model=clf2,\n",
    "    ds=split2ds[\"test\"].map(lambda x: dict(x, input=x[\"logmelspec\"])).batch(32),\n",
    "    #predict_fn=predict_with_ap_loss\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a15fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = chunk2pred.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cc2d9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/cs/clips/common_voice_cs_20424383.mp3</th>\n",
       "      <td>[8.308059e-09, 0.0003079729, 6.093462e-05, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/cs/clips/common_voice_cs_20424555.mp3</th>\n",
       "      <td>[2.471661e-07, 0.005254525, 0.00096489495, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/cs/clips/common_voice_cs_20424567.mp3</th>\n",
       "      <td>[1.87723e-07, 0.80234873, 5.8355516e-05, 0.197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/cs/clips/common_voice_cs_20424609.mp3</th>\n",
       "      <td>[1.9055422e-05, 0.7478529, 1.27799485e-05, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/cs/clips/common_voice_cs_20424636.mp3</th>\n",
       "      <td>[2.5810184e-06, 0.056320507, 0.001680822, 0.94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/zh-CN/clips/common_voice_zh-CN_22242585.mp3</th>\n",
       "      <td>[3.313049e-08, 8.7356224e-05, 0.0008840677, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/zh-CN/clips/common_voice_zh-CN_22242819.mp3</th>\n",
       "      <td>[0.00059783406, 0.08054378, 0.7682407, 0.1506177]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/zh-CN/clips/common_voice_zh-CN_22243431.mp3</th>\n",
       "      <td>[1.5969928e-05, 0.0027630564, 0.12403288, 0.87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/zh-CN/clips/common_voice_zh-CN_22243666.mp3</th>\n",
       "      <td>[9.9802e-09, 8.252818e-06, 1.6951846e-05, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/zh-CN/clips/common_voice_zh-CN_22246300.mp3</th>\n",
       "      <td>[4.939883e-07, 4.9820347e-08, 0.00077171216, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           prediction\n",
       "id                                                                                                   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [8.308059e-09, 0.0003079729, 6.093462e-05, 0.9...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [2.471661e-07, 0.005254525, 0.00096489495, 0.9...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [1.87723e-07, 0.80234873, 5.8355516e-05, 0.197...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [1.9055422e-05, 0.7478529, 1.27799485e-05, 0.2...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [2.5810184e-06, 0.056320507, 0.001680822, 0.94...\n",
       "...                                                                                               ...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [3.313049e-08, 8.7356224e-05, 0.0008840677, 0....\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [0.00059783406, 0.08054378, 0.7682407, 0.1506177]\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [1.5969928e-05, 0.0027630564, 0.12403288, 0.87...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [9.9802e-09, 8.252818e-06, 1.6951846e-05, 0.99...\n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  [4.939883e-07, 4.9820347e-08, 0.00077171216, 0...\n",
       "\n",
       "[55768 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lidbox.util import merge_chunk_predictions\n",
    "\n",
    "\n",
    "utt2pred = merge_chunk_predictions(chunk2pred)\n",
    "utt2pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436f30d",
   "metadata": {},
   "source": [
    "### Results of clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dca96ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       1.00      1.00      1.00     17341\n",
      "          ru       0.88      0.75      0.81     10379\n",
      "          en       0.87      0.87      0.87     12964\n",
      "       other       0.77      0.84      0.80     15084\n",
      "\n",
      "    accuracy                           0.88     55768\n",
      "   macro avg       0.88      0.86      0.87     55768\n",
      "weighted avg       0.88      0.88      0.88     55768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_meta = meta[meta[\"split\"]==\"test\"].join(utt2pred, how=\"outer\")\n",
    "assert not test_meta.isna().any(axis=None), \"failed to join predictions\"\n",
    "\n",
    "true_sparse = test_meta.target.to_numpy(np.int32)\n",
    "pred_dense = np.stack(test_meta.prediction.apply(np.argmax))\n",
    "\n",
    "report = classification_report(true_sparse, pred_dense, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74f41f",
   "metadata": {},
   "source": [
    "Since the results vary, it is reasonable to conduct the experiment further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf092c8",
   "metadata": {},
   "source": [
    "## Part 2. Training the classifiers to increase the discrepancy on the VOX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c03c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"new_test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"new_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "meta = pd.concat([train, test, dev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "281b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = str(meta[\"Unnamed: 0\"])\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87aa9cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /tf/datasets/vox/en_test/shrDRhToGpY__U__S133-...\n",
       "1       /tf/datasets/vox/en_test/mzfg0RGJnV8__U__S123-...\n",
       "2       /tf/datasets/vox/en_test/-_PPCH3y0eE__U__S1---...\n",
       "3       /tf/datasets/vox/en_test/DQMxvGYyu6Q__U__S0---...\n",
       "4       /tf/datasets/vox/en_test/x4lfSc7PrB0__U__S0---...\n",
       "                              ...                        \n",
       "9995    /tf/datasets/vox/en_test/KLiy94kfZI4__U__S133-...\n",
       "9996    /tf/datasets/vox/en_test/YTlliEr5LOA__U__S113-...\n",
       "9997    /tf/datasets/vox/en_test/bSs0gNq6Kkc__U__S0---...\n",
       "9998    /tf/datasets/vox/en_test/Da7c-BY6MDA__U__S2---...\n",
       "9999    /tf/datasets/vox/en_test/VWvPndMo1F8__U__S24--...\n",
       "Name: path, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ff1e458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10106    /tf/datasets/vox/en_dev/Jjwf054bhTU__U__S0---0...\n",
       "10107    /tf/datasets/vox/en_dev/6TEi0nJP5BE__U__S18---...\n",
       "10108    /tf/datasets/vox/en_dev/Zq4wKUsd0ZM__U__S10---...\n",
       "10109    /tf/datasets/vox/en_dev/8HzZXIchBhQ__U__S27---...\n",
       "10110    /tf/datasets/vox/en_dev/-J43Gvlztc8__U__S37---...\n",
       "                               ...                        \n",
       "15961    /tf/datasets/vox/en_dev/SHU3RJ03QlM__U__S1---0...\n",
       "15962    /tf/datasets/vox/en_dev/4wFO1Qqi3nQ__U__S0---0...\n",
       "15963    /tf/datasets/vox/en_dev/4zWSmjij-hs__U__S54---...\n",
       "15964    /tf/datasets/vox/en_dev/bi8wo64I57U__U__S0---0...\n",
       "15965    /tf/datasets/vox/en_dev/pqAQ4JkeOZI__U__S2---0...\n",
       "Name: path, Length: 5860, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b39ee664",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"dev\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"dev\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2378d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9279387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7068622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/ta/clips/common_voice_ta_19093662.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ta</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/es/clips/common_voice_es_20252168.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>es</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/it/clips/common_voice_it_23740290.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>it</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/pl/clips/common_voice_pl_22062475.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>pl</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/fr/clips/common_voice_fr_23921769.mp3</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>fr</td>\n",
       "      <td>dev</td>\n",
       "      <td>3</td>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---1604.030-1609.420.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0552.770-0565.180.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0100.470-0114.760.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---1384.770-1393.130.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---0687.990-0692.580.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1</td>\n",
       "      <td>/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29025 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "Unnamed: 0                                                                                              \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---...  /tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...   \n",
       "/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---05...  /tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...   \n",
       "/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---01...  /tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...   \n",
       "/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---...  /tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...   \n",
       "/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---...  /tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...   \n",
       "\n",
       "                                                   locale split  target  \\\n",
       "Unnamed: 0                                                                \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     ta   dev       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     es   dev       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     it   dev       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     pl   dev       3   \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...     fr   dev       3   \n",
       "...                                                   ...   ...     ...   \n",
       "/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---...     ru   dev       1   \n",
       "/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---05...     ru   dev       1   \n",
       "/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---01...     ru   dev       1   \n",
       "/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---...     ru   dev       1   \n",
       "/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---...     ru   dev       1   \n",
       "\n",
       "                                                                                                   id  \n",
       "Unnamed: 0                                                                                             \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "/tf/datasets/data_untar/cv-corpus-6.1-2020-12-1...  /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...  \n",
       "...                                                                                               ...  \n",
       "/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---...  /tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...  \n",
       "/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---05...  /tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...  \n",
       "/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---01...  /tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...  \n",
       "/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---...  /tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...  \n",
       "/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---...  /tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...  \n",
       "\n",
       "[29025 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39e61bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d8242de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 13:53:12.985 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.500, 1.500]\n",
      "2021-06-27 13:53:13.109 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 13:53:13.122 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 13:53:13.608 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 13:53:13.620 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 13:53:13.961 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 13:53:13.974 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 13:53:14.346 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 13:53:14.359 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    }
   ],
   "source": [
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split].sample(frac=1.0), split)\n",
    "            for split in meta.split.unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb52605",
   "metadata": {},
   "source": [
    "### But first of all test on the VOX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37758a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04b5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8014207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0145378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a7b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518df13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f83c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e1650d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [04:31,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6472115516662598, discrepancy before: 0.056961655616760254, discrepancy loss after: 0.057231366634368896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [08:58,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.13413667678833, discrepancy before: 0.05077614635229111, discrepancy loss after: 0.051046330481767654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [13:25,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.919963836669922, discrepancy before: 0.044328853487968445, discrepancy loss after: 0.042545855045318604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [17:51,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8670859336853027, discrepancy before: 0.04103769361972809, discrepancy loss after: 0.041010163724422455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [22:17,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5211219787597656, discrepancy before: 0.011340435594320297, discrepancy loss after: 0.011625243350863457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [26:42,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.6412782669067383, discrepancy before: 0.034960709512233734, discrepancy loss after: 0.034523457288742065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [31:08,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.044222831726074, discrepancy before: 0.006423259153962135, discrepancy loss after: 0.0063832481391727924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [35:34,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3240962028503418, discrepancy before: 0.004808356985449791, discrepancy loss after: 0.0041030957363545895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [39:59,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.1586060523986816, discrepancy before: 0.005310078151524067, discrepancy loss after: 0.005273367743939161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9778it [43:23,  3.76it/s]\n",
      "2991it [01:20, 37.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc: 0.586567223072052, Train acc: 0.513098955154419. Train loss (clf1): 2.1604323387145996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2991it [01:19, 37.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc (clf2): 0.5862955451011658.\n",
      "Here is an improvement from 0 to 0.5864313840866089\n",
      "Saving results\n",
      "INFO:tensorflow:Assets written to: clf1_3/model/assets\n",
      "2021-06-27 18:38:03.501 I tensorflow: Assets written to: clf1_3/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clf2_3/model/assets\n",
      "2021-06-27 18:38:05.228 I tensorflow: Assets written to: clf2_3/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: extractor/model/assets\n",
      "2021-06-27 18:38:06.786 I tensorflow: Assets written to: extractor/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:03,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4493460655212402, discrepancy before: 0.0064748008735477924, discrepancy loss after: 0.006274324841797352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1222it [05:31,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9953786134719849, discrepancy before: 0.0002067375462502241, discrepancy loss after: 0.00019329233327880502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2222it [09:57,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5613136291503906, discrepancy before: 0.002906474284827709, discrepancy loss after: 0.0026488087605684996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3222it [14:23,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5251617431640625, discrepancy before: 0.0015362376580014825, discrepancy loss after: 0.0013950061984360218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4222it [18:50,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2038086652755737, discrepancy before: 0.008787691593170166, discrepancy loss after: 0.007556402124464512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5222it [23:16,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8245667219161987, discrepancy before: 0.0002649087691679597, discrepancy loss after: 0.00020591109932865947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6222it [27:42,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8843764662742615, discrepancy before: 0.0018520738231018186, discrepancy loss after: 0.0017619709251448512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7222it [32:08,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.863968849182129, discrepancy before: 0.003809521673247218, discrepancy loss after: 0.0038248091004788876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8222it [36:34,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0268434286117554, discrepancy before: 0.0034442367032170296, discrepancy loss after: 0.003364184405654669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9222it [41:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.627358913421631, discrepancy before: 0.005002018064260483, discrepancy loss after: 0.004480269737541676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9776it [43:25,  3.75it/s]\n",
      "2991it [01:19, 37.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc: 0.6673771739006042, Train acc: 0.6325052976608276. Train loss (clf1): 1.4697000980377197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2991it [01:19, 37.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc (clf2): 0.666907012462616.\n",
      "Here is an improvement from 0.5864313840866089 to 0.6671420931816101\n",
      "Saving results\n",
      "INFO:tensorflow:Assets written to: clf1_3/model/assets\n",
      "2021-06-27 19:24:13.595 I tensorflow: Assets written to: clf1_3/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clf2_3/model/assets\n",
      "2021-06-27 19:24:15.533 I tensorflow: Assets written to: clf2_3/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: extractor/model/assets\n",
      "2021-06-27 19:24:17.095 I tensorflow: Assets written to: extractor/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "446it [02:02,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9978622198104858, discrepancy before: 2.3635129764443263e-05, discrepancy loss after: 2.488081190676894e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1446it [06:29,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1384044885635376, discrepancy before: 0.0031542563810944557, discrepancy loss after: 0.003146658418700099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [10:55,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9339596629142761, discrepancy before: 3.12356036147321e-07, discrepancy loss after: 2.8410627805897093e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3446it [15:20,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7237623929977417, discrepancy before: 0.003573259338736534, discrepancy loss after: 0.0035681030713021755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4446it [19:46,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8444103002548218, discrepancy before: 0.002823175862431526, discrepancy loss after: 0.0025392004754394293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4564it [20:18,  3.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-bc7e254f3325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_classification_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdiscrepancy_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6465\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mskip_on_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6466\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6468\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "EPOCHS = 100 \n",
    "dev_iterator = iter(split2ds[\"dev\"].batch(32).repeat(1000))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "best_acc = 0\n",
    "counter = 0\n",
    "MAX_PATIENCE = 5\n",
    "c = 0\n",
    "\n",
    "def discrepancy(out1, out2):\n",
    "    return tf.reduce_mean(tf.abs(out1 - out2))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"It is epoch number: {epoch}\")\n",
    "    avg_loss = 0\n",
    "    for i in tqdm(split2ds[\"train\"].batch(32)):\n",
    "        c += 1\n",
    "        clf1.trainable = True\n",
    "        clf2.trainable = True\n",
    "        model.trainable = True\n",
    "        target_data = next(dev_iterator)\n",
    "        s_specs = i['logmelspec']\n",
    "        t_specs = target_data['logmelspec']\n",
    "        # Train for classification\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred1 = clf1(s_specs)\n",
    "            pred2 = clf2(s_specs)\n",
    "            loss_classification_1 = loss_fn(i['target'], pred1)\n",
    "            loss_classification_2 = loss_fn(i['target'], pred2)\n",
    "            total_classification_loss = loss_classification_1 + loss_classification_2\n",
    "            avg_loss += total_classification_loss\n",
    "            \n",
    "        train_acc_metric.update_state(i['target'], pred1)\n",
    "        grads = tape.gradient(total_classification_loss, [clf1.trainable_weights, clf2.trainable_weights, model.trainable_weights])\n",
    "        optimizer.apply_gradients(zip(grads[0], clf1.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[1], clf2.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[2], model.trainable_weights))\n",
    "        # Train for discrepancy increase\n",
    "        model.trainable = False\n",
    "        with tf.GradientTape() as tape2:\n",
    "            pred1 = clf1(s_specs)\n",
    "            pred2 = clf2(s_specs)\n",
    "            loss_classification_1 = loss_fn(i['target'], pred1)\n",
    "            loss_classification_2 = loss_fn(i['target'], pred2)\n",
    "            total_classification_loss = loss_classification_1 + loss_classification_2\n",
    "            pred1 = clf1(t_specs)\n",
    "            pred2 = clf2(t_specs)\n",
    "            discrepancy_loss = discrepancy(pred1, pred2)\n",
    "            dl1 = discrepancy_loss\n",
    "            loss = total_classification_loss - discrepancy_loss\n",
    "\n",
    "        grads = tape2.gradient(loss, [clf1.trainable_weights, clf2.trainable_weights])\n",
    "        optimizer.apply_gradients(zip(grads[0], clf1.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[1], clf2.trainable_weights))\n",
    "        # Train for discrepancy decrease\n",
    "        clf1.trainable = False\n",
    "        clf2.trainable = False\n",
    "        model.trainable = True\n",
    "        dloss = 0\n",
    "        for k in range(3):\n",
    "            with tf.GradientTape() as tape3:\n",
    "                pred1 = clf1(t_specs)\n",
    "                pred2 = clf2(t_specs)\n",
    "                discrepancy_loss = discrepancy(pred1, pred2)\n",
    "                dloss = discrepancy_loss\n",
    "            grads = tape3.gradient(discrepancy_loss, model.trainable_weights)            \n",
    "            optimizer2.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        if c % 1000 == 0:\n",
    "            tqdm.write(f\"loss: {total_classification_loss}, discrepancy before: {dl1}, discrepancy loss after: {dloss}\")\n",
    "            c = 0\n",
    "    for batch in tqdm(val_data.batch(32)):\n",
    "        val_preds = clf1(batch['logmelspec'])\n",
    "        true_vals = batch['target']  \n",
    "        val_acc_metric.update_state(true_vals, val_preds)\n",
    "    new_acc = 0\n",
    "    val_acc = val_acc_metric.result()\n",
    "    new_acc += val_acc\n",
    "    val_acc_metric.reset_states()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    print(f\"Val acc: {val_acc}, Train acc: {train_acc}. Train loss (clf1): {avg_loss/9783}\")\n",
    "    for batch in tqdm(val_data.batch(32)):\n",
    "        val_preds = clf2(batch['logmelspec'])\n",
    "        true_vals = batch['target']  \n",
    "        val_acc_metric.update_state(true_vals, val_preds)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    print(f\"Val acc (clf2): {val_acc}.\")\n",
    "    new_acc += val_acc\n",
    "    if new_acc / 2 > best_acc:\n",
    "        print(f\"Here is an improvement from {best_acc} to {new_acc / 2}\\nSaving results\")\n",
    "        best_acc = new_acc / 2\n",
    "        counter = 0\n",
    "        clf1.save(\"clf1_3/model\")\n",
    "        clf2.save(\"clf2_3/model\")\n",
    "        model.save(\"extractor/model\")\n",
    "    else:\n",
    "        print(\"No improvements\")\n",
    "        counter += 1\n",
    "    if counter >= MAX_PATIENCE:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bb988d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.00000000e+00 1.19009230e-14 1.32020670e-11 1.01135653e-13]\n",
      " [1.00000000e+00 2.16983809e-11 4.74420592e-09 1.34875458e-10]\n",
      " [9.99999881e-01 1.05067799e-09 9.92498244e-08 5.55637492e-09]\n",
      " [1.00000000e+00 6.37759429e-11 1.10437242e-08 3.79018678e-10]\n",
      " [9.99997497e-01 5.62239713e-08 2.24551172e-06 2.51913491e-07]\n",
      " [1.00000000e+00 2.81078546e-12 9.56210111e-10 1.90240705e-11]\n",
      " [9.94534254e-01 5.77919185e-04 3.12577211e-03 1.76195463e-03]\n",
      " [9.99553859e-01 3.03773759e-05 3.11050972e-04 1.04725972e-04]\n",
      " [9.99991536e-01 2.46231849e-07 7.14492262e-06 1.03742855e-06]\n",
      " [9.99998927e-01 2.08856150e-08 1.03339642e-06 9.75192265e-08]\n",
      " [9.99999404e-01 1.03782938e-08 5.97366068e-07 4.98906942e-08]\n",
      " [9.99999881e-01 7.76933629e-10 7.83425449e-08 4.16069090e-09]\n",
      " [9.99990582e-01 2.83229298e-07 7.97335997e-06 1.18636899e-06]\n",
      " [1.00000000e+00 4.66268274e-11 8.64002647e-09 2.80740209e-10]\n",
      " [9.99965429e-01 1.38509154e-06 2.76613573e-05 5.43059423e-06]\n",
      " [9.99775350e-01 1.33777503e-05 1.63577890e-04 4.77227914e-05]\n",
      " [9.99873519e-01 6.70364216e-06 9.51846523e-05 2.46123709e-05]\n",
      " [9.99862671e-01 7.40230053e-06 1.02874852e-04 2.70654909e-05]\n",
      " [9.99228358e-01 5.82401262e-05 5.18000685e-04 1.95410030e-04]\n",
      " [9.92551446e-01 8.27031501e-04 4.13767574e-03 2.48387991e-03]\n",
      " [9.99885082e-01 5.96922791e-06 8.69112846e-05 2.20221973e-05]\n",
      " [9.99940038e-01 2.71707381e-06 4.69028637e-05 1.03581360e-05]\n",
      " [9.98628616e-01 1.14856186e-04 8.81885178e-04 3.74613592e-04]\n",
      " [9.99503851e-01 3.44807086e-05 3.43519001e-04 1.18246258e-04]\n",
      " [9.97067630e-01 2.80005974e-04 1.77242165e-03 8.79932079e-04]\n",
      " [9.98896003e-01 8.89461371e-05 7.21814111e-04 2.93214660e-04]\n",
      " [9.99768078e-01 1.38918786e-05 1.68484228e-04 4.94790802e-05]\n",
      " [9.99960661e-01 1.62726064e-06 3.13845376e-05 6.33741138e-06]\n",
      " [9.99746740e-01 1.54362733e-05 1.82993710e-04 5.47388736e-05]\n",
      " [9.99961734e-01 1.57611407e-06 3.06088186e-05 6.14639202e-06]\n",
      " [9.99967694e-01 1.27627538e-06 2.59433327e-05 5.02103421e-06]\n",
      " [9.99987006e-01 4.18614604e-07 1.08296854e-05 1.72515672e-06]], shape=(32, 4), dtype=float32) tf.Tensor([0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "target_data = next(dev_iterator)\n",
    "t_specs = target_data['logmelspec']\n",
    "print(clf2(t_specs), target_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d6bd6bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_26/kernel:0' shape=(512, 128) dtype=float32, numpy=\n",
       " array([[-0.04428463, -0.06575986, -0.03093002, ..., -0.06438525,\n",
       "         -0.06454992, -0.03146683],\n",
       "        [-0.06528097, -0.06506743, -0.15744567, ..., -0.09292911,\n",
       "         -0.01714528, -0.01219531],\n",
       "        [ 0.0603695 , -0.04678904, -0.00422427, ..., -0.08944634,\n",
       "          0.06902291, -0.05208739],\n",
       "        ...,\n",
       "        [-0.14467703, -0.0124551 , -0.11538287, ...,  0.01766187,\n",
       "          0.11588152,  0.07392925],\n",
       "        [-0.02426761,  0.04343619,  0.1003718 , ..., -0.0510636 ,\n",
       "         -0.12005099,  0.0778337 ],\n",
       "        [ 0.02266992,  0.03148512,  0.04171593, ..., -0.03963193,\n",
       "         -0.00856541, -0.01874579]], dtype=float32)>,\n",
       " <tf.Variable 'dense_26/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.35369572, -0.07690878, -0.16411977, -0.10389522, -0.03021821,\n",
       "        -0.02824787, -0.18758969, -0.14436996,  0.0174201 , -0.10246152,\n",
       "        -0.17557439,  0.45739302, -0.14029697, -0.16773385, -0.16950361,\n",
       "        -0.1676454 , -0.09059268, -0.17886525,  0.0185771 , -0.11714157,\n",
       "         0.11504092,  0.5615999 ,  0.03917438, -0.18372843, -0.07052724,\n",
       "         0.02678205, -0.07938059, -0.02800593, -0.15252593, -0.1510261 ,\n",
       "        -0.16735353,  0.03719574,  0.077843  , -0.14918886,  0.16305703,\n",
       "        -0.05298941,  0.39798304,  1.0407623 , -0.02197792,  0.18000615,\n",
       "        -0.22415572, -0.13489161, -0.18721417, -0.21396726,  0.05990481,\n",
       "        -0.07653481, -0.09584756,  0.16963041, -0.07869411, -0.02140461,\n",
       "        -0.0692031 ,  0.41411516, -0.33211   ,  0.323669  , -0.20545931,\n",
       "        -0.2609843 , -0.24840471, -0.21234903, -0.04092748, -0.13324158,\n",
       "         0.02732303, -0.00804135, -0.05288995, -0.07124615, -0.03476558,\n",
       "         0.02928679,  0.04982782, -0.08167565, -0.12950961, -0.09545107,\n",
       "        -0.09176293, -0.08440796, -0.02884843, -0.16284122, -0.17533657,\n",
       "        -0.25433794, -0.08873019, -0.1424201 , -0.1783682 , -0.09070914,\n",
       "        -0.17948261,  0.10875827, -0.12788856, -0.04161549, -0.10558102,\n",
       "        -0.12403837, -0.01688191, -0.15669335, -0.14996576,  0.04052056,\n",
       "        -0.12203944, -0.09476915, -0.07203185, -0.28817004,  0.33765352,\n",
       "         0.11337601, -0.22738786, -0.2884999 , -0.12667683, -0.20554243,\n",
       "         0.03331566, -0.17446665,  0.08151562, -0.18143952, -0.16716611,\n",
       "        -0.18461642,  0.17863558, -0.09511893, -0.03784251, -0.1361787 ,\n",
       "         0.03080257,  1.2133788 , -0.04406642,  0.3773527 , -0.62245864,\n",
       "         0.13437958, -0.24544458, -0.067348  ,  0.01446854, -0.16606525,\n",
       "         0.26385576, -0.7492229 ,  0.39307395, -0.09144152, -0.109225  ,\n",
       "        -0.03319687, -0.06781959, -0.1327363 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_27/kernel:0' shape=(128, 4) dtype=float32, numpy=\n",
       " array([[ 6.69373497e-02,  5.86417615e-02, -9.07749906e-02,\n",
       "          4.86767478e-02],\n",
       "        [-2.71804005e-01, -7.33078420e-02, -2.08271310e-01,\n",
       "         -9.27369390e-03],\n",
       "        [-5.61736710e-03,  3.04405242e-02,  5.40061332e-02,\n",
       "          6.42695799e-02],\n",
       "        [ 6.73591942e-02,  1.61830056e-02,  2.10445677e-03,\n",
       "          1.14995368e-01],\n",
       "        [ 1.80458948e-01, -3.10018770e-02,  8.30604434e-02,\n",
       "          2.93620862e-02],\n",
       "        [-2.68929754e-03, -1.36634588e-01,  3.05262674e-02,\n",
       "          1.79931354e-02],\n",
       "        [-1.00458018e-01, -5.81383370e-02,  1.34028554e-01,\n",
       "          1.15237739e-02],\n",
       "        [-8.61316696e-02,  2.19187029e-02, -1.54228181e-01,\n",
       "         -6.47770986e-02],\n",
       "        [ 7.44332522e-02,  6.79019243e-02,  1.09848529e-02,\n",
       "          4.20323461e-02],\n",
       "        [ 3.53839286e-02, -2.02531815e-02,  6.37044683e-02,\n",
       "          3.07252761e-02],\n",
       "        [ 1.64910667e-02,  9.78482813e-02,  2.37046573e-02,\n",
       "          7.98456222e-02],\n",
       "        [-7.44176432e-02, -2.29554519e-01, -2.57727712e-01,\n",
       "          6.94323555e-02],\n",
       "        [ 2.31779944e-02,  8.08069333e-02,  3.02844041e-04,\n",
       "         -1.68799900e-03],\n",
       "        [-1.64818034e-01,  1.80999432e-02,  5.22303358e-02,\n",
       "         -5.80875017e-02],\n",
       "        [-8.43482539e-02, -4.62488830e-02,  1.02119327e-01,\n",
       "         -2.10239410e-01],\n",
       "        [ 5.34085138e-03, -1.34598883e-02,  2.99856663e-02,\n",
       "         -2.46868487e-02],\n",
       "        [-2.39716917e-01,  1.43247381e-01, -7.44477361e-02,\n",
       "         -1.85760275e-01],\n",
       "        [-3.92342880e-02,  4.45930939e-03, -2.11117398e-02,\n",
       "         -1.78530607e-02],\n",
       "        [-1.41303822e-01, -1.06841624e-01, -1.98795184e-01,\n",
       "         -1.67456865e-01],\n",
       "        [ 2.28801891e-01,  1.07291482e-01,  1.38234004e-01,\n",
       "         -4.83381264e-02],\n",
       "        [-1.18471026e-01, -1.46111429e-01, -4.43462953e-02,\n",
       "          2.42671836e-02],\n",
       "        [-3.70204002e-01, -1.92261040e-01, -1.76334321e-01,\n",
       "          2.93597076e-02],\n",
       "        [-1.36675701e-01, -1.31270453e-01, -1.32911056e-01,\n",
       "         -7.75792077e-02],\n",
       "        [-4.75421809e-02, -2.84962896e-02, -5.90751916e-02,\n",
       "         -5.07426783e-02],\n",
       "        [-4.34048586e-02, -8.94371886e-03, -8.03265944e-02,\n",
       "         -5.50091751e-02],\n",
       "        [-2.40751132e-01,  8.93080831e-02, -1.74367055e-01,\n",
       "          7.76036978e-02],\n",
       "        [-4.58094999e-02, -7.19597191e-03, -3.66732776e-02,\n",
       "         -3.08324043e-02],\n",
       "        [ 9.37257260e-02,  3.30020934e-02, -8.70165452e-02,\n",
       "         -5.76090626e-02],\n",
       "        [-1.19622931e-01, -1.77586272e-01, -3.10196150e-02,\n",
       "          2.28332058e-02],\n",
       "        [-6.34760503e-03,  9.22656711e-03,  5.61423134e-03,\n",
       "         -2.96940580e-02],\n",
       "        [ 3.72436382e-02, -1.32757593e-02, -7.17803463e-02,\n",
       "         -2.06414983e-02],\n",
       "        [ 8.00159276e-02,  1.07766218e-01,  4.55218852e-02,\n",
       "          2.63321549e-02],\n",
       "        [-6.06044047e-02, -8.92233700e-02, -1.71108603e-01,\n",
       "         -1.22721359e-01],\n",
       "        [-1.12884074e-01, -2.45800808e-01,  6.79871961e-02,\n",
       "         -1.73518240e-01],\n",
       "        [-1.67410478e-01, -1.89852670e-01, -1.01802446e-01,\n",
       "         -6.11662157e-02],\n",
       "        [ 1.00000344e-01,  7.37020597e-02,  7.60049606e-03,\n",
       "          9.20680016e-02],\n",
       "        [ 2.10688580e-02, -1.88184217e-01, -1.17217951e-01,\n",
       "          1.32622391e-01],\n",
       "        [-7.15128720e-01,  2.30288561e-02, -5.21175191e-02,\n",
       "          3.34706083e-02],\n",
       "        [-1.06174976e-01, -1.53693827e-02, -7.45113343e-02,\n",
       "         -1.89963579e-02],\n",
       "        [-1.44081384e-01, -3.03573400e-01, -1.56613797e-01,\n",
       "          1.00962007e-02],\n",
       "        [-1.41840696e-01, -1.02238469e-01, -3.70193720e-02,\n",
       "          9.10890624e-02],\n",
       "        [ 8.89438614e-02,  4.93087173e-02,  9.75090191e-02,\n",
       "          9.25529003e-02],\n",
       "        [-7.78678851e-03,  2.63060033e-02, -2.80543175e-02,\n",
       "          6.13354295e-02],\n",
       "        [-1.04916565e-01, -8.22160393e-03,  2.62239780e-02,\n",
       "          1.05560750e-01],\n",
       "        [ 1.32183999e-01, -7.72147812e-03,  7.13382214e-02,\n",
       "          4.09254245e-02],\n",
       "        [-1.58527762e-01, -2.29846686e-02, -3.72256637e-02,\n",
       "         -3.66336107e-02],\n",
       "        [-4.61390428e-02, -2.22455099e-01, -2.22772509e-01,\n",
       "         -7.81960413e-02],\n",
       "        [ 1.09005347e-01, -6.02126420e-02, -2.39770487e-02,\n",
       "          1.61446333e-02],\n",
       "        [-4.16868955e-01,  5.05677313e-02, -1.01508491e-01,\n",
       "         -2.59063601e-01],\n",
       "        [-6.29979596e-02,  5.86303771e-02,  3.97252068e-02,\n",
       "          6.35453910e-02],\n",
       "        [ 6.37437776e-02,  3.26885618e-02,  6.02725297e-02,\n",
       "          3.84755842e-02],\n",
       "        [ 4.23685573e-02, -6.37667626e-03, -8.35710093e-02,\n",
       "          7.84689412e-02],\n",
       "        [-8.14042389e-02, -1.55349700e-02, -8.21606144e-02,\n",
       "         -9.95347351e-02],\n",
       "        [ 2.95763835e-02, -2.82086164e-01, -2.17137888e-01,\n",
       "          4.50869873e-02],\n",
       "        [-3.38091329e-02, -1.10169630e-02,  6.49033785e-02,\n",
       "         -5.73198311e-02],\n",
       "        [ 6.72821850e-02,  1.70412332e-01,  5.62196337e-02,\n",
       "          7.42525905e-02],\n",
       "        [ 1.15490081e-02, -5.37041798e-02, -5.85497878e-02,\n",
       "         -4.26719859e-02],\n",
       "        [ 5.19034117e-02,  1.43557549e-01,  1.02021761e-01,\n",
       "          1.18544839e-01],\n",
       "        [-6.14522882e-02,  6.05336651e-02,  7.76085705e-02,\n",
       "          1.00549944e-01],\n",
       "        [-1.01684108e-01,  1.74847525e-02,  2.72952132e-02,\n",
       "         -8.43716487e-02],\n",
       "        [-6.61064386e-02,  2.58227549e-02,  5.95185794e-02,\n",
       "          9.03945602e-03],\n",
       "        [-3.37667130e-02,  2.75530163e-02, -2.08341822e-01,\n",
       "         -6.39237687e-02],\n",
       "        [-3.37321544e-03, -1.44276947e-01, -8.90370011e-02,\n",
       "          4.27308641e-02],\n",
       "        [-2.13974953e-01, -7.46700913e-02, -2.66251326e-01,\n",
       "         -7.49705210e-02],\n",
       "        [-1.80173352e-01, -4.51004272e-03, -2.24194620e-02,\n",
       "         -9.29874554e-02],\n",
       "        [-1.12008400e-01, -5.38606122e-02, -1.51128918e-01,\n",
       "         -5.07881343e-02],\n",
       "        [ 1.77308202e-01,  6.45314455e-02,  1.29835501e-01,\n",
       "          8.04198012e-02],\n",
       "        [-1.18246488e-01, -2.55696867e-02, -3.32889445e-02,\n",
       "          9.92345288e-02],\n",
       "        [-9.86335427e-02, -1.23951338e-01, -1.70496672e-01,\n",
       "         -1.70170188e-01],\n",
       "        [-1.36536941e-01, -1.05084009e-01, -3.35391201e-02,\n",
       "         -1.27521172e-01],\n",
       "        [-1.10617511e-01,  7.20332712e-02, -1.17723353e-01,\n",
       "         -8.12188163e-02],\n",
       "        [-1.03697054e-01, -8.16728026e-02,  1.24970324e-01,\n",
       "         -5.08459397e-02],\n",
       "        [-7.49572739e-02,  7.15940399e-03, -1.11867391e-01,\n",
       "         -7.58585185e-02],\n",
       "        [ 2.68460605e-02,  4.51017246e-02, -5.21548800e-02,\n",
       "          2.39030588e-02],\n",
       "        [ 3.48676667e-02, -2.39161197e-02, -2.65145972e-02,\n",
       "         -2.01471969e-02],\n",
       "        [-1.62720792e-02,  3.88430315e-03, -4.54847002e-03,\n",
       "         -2.94022877e-02],\n",
       "        [-1.92552865e-01, -1.50287468e-02, -1.60981864e-01,\n",
       "         -6.81869686e-02],\n",
       "        [-6.27331808e-03, -7.25497156e-02, -3.22101377e-02,\n",
       "         -2.06683781e-02],\n",
       "        [-1.70919955e-01, -8.74872208e-02, -1.05804808e-01,\n",
       "         -4.24752869e-02],\n",
       "        [-1.42032474e-01, -3.29610668e-02, -8.64237025e-02,\n",
       "         -1.96496636e-01],\n",
       "        [-1.28615707e-01, -1.27671495e-01, -8.53202865e-02,\n",
       "         -1.04063697e-01],\n",
       "        [-1.67984534e-02,  1.55742809e-01, -1.01723447e-01,\n",
       "          1.07437626e-01],\n",
       "        [-1.44486176e-03, -1.70137137e-01, -1.22968279e-01,\n",
       "         -7.39317015e-02],\n",
       "        [-2.30728459e-04, -1.70673192e-01, -1.83802277e-01,\n",
       "         -1.12878218e-01],\n",
       "        [-2.31279850e-01,  2.08785664e-02, -1.70005374e-02,\n",
       "          8.63478705e-02],\n",
       "        [ 1.09492444e-01,  7.54034519e-02,  1.10300213e-01,\n",
       "          5.22683635e-02],\n",
       "        [-1.61941499e-02,  4.97675203e-02, -1.15315720e-01,\n",
       "         -7.39598125e-02],\n",
       "        [-2.58079112e-01, -1.05197448e-02, -1.21304348e-01,\n",
       "         -7.72991329e-02],\n",
       "        [ 1.22569144e-01,  1.18229255e-01,  1.31878629e-01,\n",
       "          9.92879644e-02],\n",
       "        [-5.10358959e-02, -1.41977862e-01, -9.96953547e-02,\n",
       "         -9.99516770e-02],\n",
       "        [ 7.52513260e-02,  8.61833245e-02,  1.38030022e-01,\n",
       "          4.83430400e-02],\n",
       "        [-8.75730067e-02,  1.74968783e-02, -5.10026887e-02,\n",
       "          1.58265293e-01],\n",
       "        [ 8.00818279e-02,  1.46464512e-01,  1.04464702e-01,\n",
       "          2.50781942e-02],\n",
       "        [ 1.98801351e-03,  1.94068402e-02,  7.72014167e-03,\n",
       "          5.69302104e-02],\n",
       "        [-5.86641729e-02, -6.77272081e-02, -7.93435574e-02,\n",
       "          5.11252657e-02],\n",
       "        [-1.52258486e-01, -5.86125888e-02, -2.85136723e-03,\n",
       "         -8.10384692e-04],\n",
       "        [-3.57396975e-02,  2.16845740e-02, -2.39972528e-02,\n",
       "          6.49979757e-03],\n",
       "        [ 4.36470751e-03, -6.64776564e-02,  3.72720137e-02,\n",
       "         -1.32191405e-02],\n",
       "        [-3.04848701e-01, -4.06482741e-02,  8.26982707e-02,\n",
       "          2.91906390e-02],\n",
       "        [-4.39556949e-02, -4.93647605e-02,  8.00023228e-02,\n",
       "          4.62586582e-02],\n",
       "        [-1.39826298e-01, -4.34973612e-02, -1.50858127e-02,\n",
       "         -1.53087184e-01],\n",
       "        [-3.30822379e-03, -1.44547271e-02,  3.69340144e-02,\n",
       "         -3.40409428e-02],\n",
       "        [-7.04771876e-02, -1.27125144e-01, -2.04512328e-02,\n",
       "         -1.16656147e-01],\n",
       "        [-1.53067887e-01, -1.43762335e-01, -1.58839837e-01,\n",
       "         -1.87154070e-01],\n",
       "        [-5.32036573e-02, -1.75018031e-02, -6.62595034e-02,\n",
       "         -2.05341764e-02],\n",
       "        [ 1.62701961e-02, -2.41196360e-02, -1.17399395e-02,\n",
       "          3.46192368e-03],\n",
       "        [-7.00743645e-02, -2.26471927e-02, -1.03661887e-01,\n",
       "         -3.22835594e-02],\n",
       "        [-3.64211380e-01, -1.54687345e-01, -1.65420070e-01,\n",
       "         -6.63792044e-02],\n",
       "        [ 6.90496585e-04,  1.64440677e-01,  1.16387056e-02,\n",
       "         -4.04063277e-02],\n",
       "        [-4.42614332e-02,  1.17266834e-01, -1.75589263e-01,\n",
       "         -1.24121539e-01],\n",
       "        [-7.57298060e-03,  1.05969846e-01,  2.32784245e-02,\n",
       "          4.27057780e-02],\n",
       "        [-7.40802646e-01,  1.35595828e-01,  1.11348741e-01,\n",
       "          1.15221433e-01],\n",
       "        [-3.08476865e-01, -2.07390869e-03, -7.27593899e-02,\n",
       "         -7.33904913e-02],\n",
       "        [-1.04648128e-01, -1.51034608e-01, -5.73879182e-02,\n",
       "          2.22370520e-01],\n",
       "        [-2.31995061e-01, -8.41631517e-02, -6.23273337e-03,\n",
       "         -1.59002364e-01],\n",
       "        [ 8.62914994e-02, -1.18138231e-01,  9.61700380e-02,\n",
       "          8.90890062e-02],\n",
       "        [-8.18963200e-02,  3.13301347e-02, -5.45615591e-02,\n",
       "         -4.01546396e-02],\n",
       "        [-1.28437728e-01, -7.43269175e-02,  3.15693356e-02,\n",
       "         -9.30523872e-02],\n",
       "        [-1.08824030e-01,  6.96061254e-02,  8.06249753e-02,\n",
       "          8.93495604e-02],\n",
       "        [-1.13316283e-01, -2.33242333e-01, -1.17265992e-01,\n",
       "         -1.03906989e-01],\n",
       "        [-1.50001317e-01, -7.79053867e-02, -9.55231953e-05,\n",
       "          1.58932209e-02],\n",
       "        [-1.32224504e-02, -1.05238065e-01, -8.53349790e-02,\n",
       "         -1.01405509e-01],\n",
       "        [-1.17512107e-01, -7.06700385e-02, -1.42389983e-01,\n",
       "          1.63152963e-02],\n",
       "        [-2.59745330e-01, -1.34361118e-01, -1.96244761e-01,\n",
       "          4.88199443e-02],\n",
       "        [ 5.63910976e-02,  1.77340191e-02,  4.11180928e-02,\n",
       "          2.04996020e-02],\n",
       "        [-9.86186489e-02, -1.79863244e-01, -1.10752493e-01,\n",
       "          2.83043217e-02],\n",
       "        [-7.39109665e-02,  4.95474972e-02, -3.73740867e-02,\n",
       "          8.03077519e-02],\n",
       "        [-9.69938487e-02,  3.82501632e-02,  3.85266775e-03,\n",
       "         -1.72104031e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_27/bias:0' shape=(4,) dtype=float32, numpy=array([-0.96755403, -0.11138831, -0.22014761,  0.6573715 ], dtype=float32)>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87bd23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = predict_with_model(\n",
    "    model=clf2,\n",
    "    ds=split2ds[\"test\"].map(lambda x: dict(x, input=x[\"logmelspec\"])).batch(32),\n",
    "    #predict_fn=predict_with_ap_loss\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dfce34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk2pred = chunk2pred.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e5782d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>locale</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56701</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>kz</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>ru</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110475</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>rw</td>\n",
       "      <td>train</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45384</th>\n",
       "      <td>/tf/datasets/data_untar/cv-corpus-6.1-2020-12-...</td>\n",
       "      <td>en</td>\n",
       "      <td>train</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---1604.030-1609.420.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0552.770-0565.180.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0100.470-0114.760.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---1384.770-1393.130.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---0687.990-0692.580.mp3</th>\n",
       "      <td>/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...</td>\n",
       "      <td>ru</td>\n",
       "      <td>dev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162610 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 path  \\\n",
       "id                                                                                                      \n",
       "1486                                                /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "56701                                               /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "3364                                                /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "110475                                              /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "45384                                               /tf/datasets/data_untar/cv-corpus-6.1-2020-12-...   \n",
       "...                                                                                               ...   \n",
       "/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---...  /tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251--...   \n",
       "/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---05...  /tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---0...   \n",
       "/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---01...  /tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---0...   \n",
       "/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---...  /tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208--...   \n",
       "/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---...  /tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100--...   \n",
       "\n",
       "                                                   locale  split  target  \n",
       "id                                                                        \n",
       "1486                                                   ru  train     1.0  \n",
       "56701                                                  kz  train     0.0  \n",
       "3364                                                   ru  train     1.0  \n",
       "110475                                                 rw  train     3.0  \n",
       "45384                                                  en  train     2.0  \n",
       "...                                                   ...    ...     ...  \n",
       "/tf/datasets/vox/ru_dev/BH8c4SbgXss__U__S251---...     ru    dev     1.0  \n",
       "/tf/datasets/vox/ru_dev/--RxvUW3u7M__U__S0---05...     ru    dev     1.0  \n",
       "/tf/datasets/vox/ru_dev/kZ8LKE26cl0__U__S1---01...     ru    dev     1.0  \n",
       "/tf/datasets/vox/ru_dev/ya9uyy12vvM__U__S208---...     ru    dev     1.0  \n",
       "/tf/datasets/vox/ru_dev/lUhjPr7Lcu8__U__S100---...     ru    dev     1.0  \n",
       "\n",
       "[162610 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2463dd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0003.940-0020.570.mp3</th>\n",
       "      <td>[0.82074064, 0.036507558, 0.05600509, 0.086746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0743.730-0757.100.mp3</th>\n",
       "      <td>[0.7609731, 0.050528564, 0.07821112, 0.11028719]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0650.920-0661.560.mp3</th>\n",
       "      <td>[0.99982405, 1.17218315e-05, 0.00012380008, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0692.790-0704.510.mp3</th>\n",
       "      <td>[0.99906653, 9.269332e-05, 0.0005545609, 0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100---0705.010-0711.610.mp3</th>\n",
       "      <td>[0.9915779, 0.0011870286, 0.0039456706, 0.0032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0219.180-0230.690.mp3</th>\n",
       "      <td>[0.9704744, 0.0048984527, 0.01188823, 0.012738...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0230.690-0247.370.mp3</th>\n",
       "      <td>[0.9708305, 0.005451752, 0.0102613745, 0.01345...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0247.370-0257.750.mp3</th>\n",
       "      <td>[0.9644639, 0.006060426, 0.01391795, 0.015557733]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---0277.000-0287.980.mp3</th>\n",
       "      <td>[0.80379754, 0.04677399, 0.054464877, 0.09496365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---0301.200-0306.760.mp3</th>\n",
       "      <td>[0.56486857, 0.08920277, 0.1341035, 0.21182513]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36053 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           prediction\n",
       "id                                                                                                   \n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...  [0.82074064, 0.036507558, 0.05600509, 0.086746...\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S0---0...   [0.7609731, 0.050528564, 0.07821112, 0.11028719]\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.99982405, 1.17218315e-05, 0.00012380008, 4....\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.99906653, 9.269332e-05, 0.0005545609, 0.000...\n",
       "/tf/datasets/vox/en_test/-BwrRlUdfEs__U__S100--...  [0.9915779, 0.0011870286, 0.0039456706, 0.0032...\n",
       "...                                                                                               ...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9704744, 0.0048984527, 0.01188823, 0.012738...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9708305, 0.005451752, 0.0102613745, 0.01345...\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.9644639, 0.006060426, 0.01391795, 0.015557733]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S20---...  [0.80379754, 0.04677399, 0.054464877, 0.09496365]\n",
       "/tf/datasets/vox/ru_test/ztSbqN-mPtM__U__S52---...    [0.56486857, 0.08920277, 0.1341035, 0.21182513]\n",
       "\n",
       "[36053 rows x 1 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lidbox.util import merge_chunk_predictions\n",
    "\n",
    "\n",
    "utt2pred = merge_chunk_predictions(chunk2pred)\n",
    "utt2pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "750c1658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          kz       0.39      0.99      0.55     13946\n",
      "          ru       0.00      0.00      0.00     12107\n",
      "          en       0.47      0.00      0.00     10000\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38     36053\n",
      "   macro avg       0.21      0.25      0.14     36053\n",
      "weighted avg       0.28      0.38      0.22     36053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_meta = meta[meta[\"split\"]==\"test\"].join(utt2pred, how=\"outer\")\n",
    "assert not test_meta.isna().any(axis=None), \"failed to join predictions\"\n",
    "\n",
    "true_sparse = test_meta.target.to_numpy(np.int32)\n",
    "pred_dense = np.stack(test_meta.prediction.apply(np.argmax))\n",
    "\n",
    "report = classification_report(true_sparse, pred_dense, target_names=list(targets.keys()), labels=range(4))\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b17cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d41b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98518935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8aff0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d24f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ceab350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 08:00:22.330 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.500, 1.500]\n",
      "2021-06-27 08:00:22.454 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:22.466 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 08:00:22.933 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:22.945 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 08:00:23.300 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:23.313 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "Model: \"x-vector-frequency-attention\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 40)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "channel_dropout (SpatialDropout (None, None, 40)     0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "frame1 (Conv1D)                 (None, None, 512)    102912      channel_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "frame2 (Conv1D)                 (None, None, 512)    786944      frame1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame3 (Conv1D)                 (None, None, 512)    786944      frame2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame4 (Conv1D)                 (None, None, 512)    262656      frame3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "frame5 (Conv1D)                 (None, None, 1500)   769500      frame4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_1 (Dense)                    (None, None, 64)     96000       frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Wf_2 (Dense)                    (None, None, 60)     3840        Wf_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "expand_bin_weight_dim (Reshape) (None, None, 60, 1)  0           Wf_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "partition_freq_bins (Reshape)   (None, None, 60, 25) 0           frame5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "freq_attention (Multiply)       (None, None, 60, 25) 0           expand_bin_weight_dim[0][0]      \n",
      "                                                                 partition_freq_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "merge_weighted_bins (Reshape)   (None, None, 1500)   0           freq_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stats_pooling (GlobalMeanStddev (None, 3000)         0           merge_weighted_bins[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "segment1 (Dense)                (None, 512)          1536512     stats_pooling[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "segment2 (Dense)                (None, 512)          262656      segment1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 4)            2052        segment2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "log_softmax (Activation)        (None, 4)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,610,016\n",
      "Trainable params: 4,610,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "2021-06-27 08:00:26.118 I lidbox.data.steps: Applying random resampling to signals with a random speed ratio chosen uniformly at random from [0.500, 1.500]\n",
      "2021-06-27 08:00:26.142 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:26.154 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 08:00:26.520 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:26.533 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 08:00:26.856 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:26.869 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n",
      "2021-06-27 08:00:27.217 I lidbox.data.steps: Repeating all signals until they are at least 3200 ms\n",
      "2021-06-27 08:00:27.230 I lidbox.data.steps: Dividing every signal in the dataset into new signals by creating signal chunks of length 3200 ms and offset 800 ms. Maximum amount of padding allowed in the last chunk is 0 ms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is epoch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:12, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: {{function_node __inference_Dataset_map_batch_extract_features_10757}} OOM when allocating tensor with shape[10176,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node PartitionedCall/stft/rfft/Pad}}]]\n\t [[strided_slice_3/_138]]\n  (1) Resource exhausted: {{function_node __inference_Dataset_map_batch_extract_features_10757}} OOM when allocating tensor with shape[10176,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node PartitionedCall/stft/rfft/Pad}}]]\n0 successful operations.\n0 derived errors ignored. [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-37ce1c39d100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"It is epoch number: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit2ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: {{function_node __inference_Dataset_map_batch_extract_features_10757}} OOM when allocating tensor with shape[10176,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node PartitionedCall/stft/rfft/Pad}}]]\n\t [[strided_slice_3/_138]]\n  (1) Resource exhausted: {{function_node __inference_Dataset_map_batch_extract_features_10757}} OOM when allocating tensor with shape[10176,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node PartitionedCall/stft/rfft/Pad}}]]\n0 successful operations.\n0 derived errors ignored. [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Automatically reload imported modules that are changed outside this notebook\n",
    "# More pixels in figures\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "#test = test.sample(30000, replace=False)\n",
    "meta = pd.concat([train, test, dev])\n",
    "\n",
    "meta.loc[meta[\"locale\"] != \"kz\", \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" +  meta.loc[meta[\"locale\"] != \"kz\"][\"locale\"] + \"/clips/\" + meta.loc[meta[\"locale\"] != \"kz\"][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "meta[\"id\"] = meta[\"path\"]\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "from lidbox.features import audio, cmvn\n",
    "import lidbox.data.steps as ds_steps\n",
    "\n",
    "\n",
    "TF_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def metadata_to_dataset_input(meta):\n",
    "    return {\n",
    "        \"id\": tf.constant(meta.id, tf.string),\n",
    "        \"path\": tf.constant(meta.path, tf.string),\n",
    "        \"target\": tf.constant(meta.target, tf.int32),\n",
    "        \"split\": tf.constant(meta.split, tf.string),\n",
    "    }\n",
    "\n",
    "def read_mp3(x):\n",
    "    s, r = audio.read_mp3(x[\"path\"])\n",
    "    out_rate = 16000\n",
    "    s = audio.resample(s, r, out_rate)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    s = audio.remove_silence(s, out_rate)\n",
    "    return dict(x, signal=s, sample_rate=out_rate)\n",
    "\n",
    "\n",
    "def random_filter(x):\n",
    "    def scipy_filter(s, N=10):\n",
    "        b = np_rng.normal(0, 1, N)\n",
    "        return scipy.signal.lfilter(b, 1.0, s).astype(np.float32), b\n",
    "    s, _ = tf.numpy_function(\n",
    "        scipy_filter,\n",
    "        [x[\"signal\"]],\n",
    "        [tf.float32, tf.float64],\n",
    "        name=\"np_random_filter\")\n",
    "    s = tf.cast(s, tf.float32)\n",
    "    s = audio.peak_normalize(s, dBFS=-3.0)\n",
    "    return dict(x, signal=s)\n",
    "\n",
    "\n",
    "def random_speed_change(ds):\n",
    "    return ds_steps.random_signal_speed_change(ds, min=0.5, max=1.5, flag=None)\n",
    "\n",
    "\n",
    "def create_signal_chunks(ds):\n",
    "    ds = ds_steps.repeat_too_short_signals(ds, 3200)\n",
    "    ds = ds_steps.create_signal_chunks(ds, 3200, 800)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def batch_extract_features(x):\n",
    "    with tf.device(\"GPU\"):\n",
    "        signals, rates = x[\"signal\"], x[\"sample_rate\"]\n",
    "        S = audio.spectrograms(signals, rates[0])\n",
    "        S = audio.linear_to_mel(S, rates[0])\n",
    "        S = tf.math.log(S + 1e-6)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(S)\n",
    "        mfccs = mfccs[...,1:21]\n",
    "        S = cmvn(S, normalize_variance=False)\n",
    "        mfccs_cmvn = cmvn(mfccs)\n",
    "\n",
    "        #S = tfio.audio.freq_mask(S, param=10)\n",
    "        #S = tfio.audio.time_mask(S, param=10)\n",
    "    return dict(x, logmelspec=S, mfccs=mfccs)\n",
    "\n",
    "\n",
    "def pipeline_from_meta(data, split):\n",
    "    if split == \"train\":\n",
    "        data = data.sample(frac=1, random_state=np_rng.bit_generator)\n",
    "\n",
    "    ds = (tf.data.Dataset\n",
    "            .from_tensor_slices(metadata_to_dataset_input(data))\n",
    "            .map(read_mp3, num_parallel_calls=TF_AUTOTUNE))\n",
    "\n",
    "    if split == \"train\":\n",
    "        return (ds\n",
    "            .apply(random_speed_change)\n",
    "           #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(32)\n",
    "            .map(random_filter, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(32)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch())\n",
    "    else:\n",
    "        return (ds\n",
    "            .apply(create_signal_chunks)\n",
    "            .batch(32)\n",
    "            .map(batch_extract_features, num_parallel_calls=TF_AUTOTUNE)\n",
    "            .unbatch()\n",
    "            #.cache(os.path.join(cachedir, \"data\", split))\n",
    "            .prefetch(1))\n",
    "\n",
    "\n",
    "val_data = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}\n",
    "val_data = val_data['dev']\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    " \n",
    "   Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    Layer,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming spectral features (Batch, Time, Channels), where freq. channels are always last\n",
    "TIME_AXIS = 1\n",
    "STDDEV_SQRT_MIN_CLIP = 1e-10\n",
    "\n",
    "\n",
    "class GlobalMeanStddevPooling1D(Layer):\n",
    "    \"\"\"\n",
    "    Compute arithmetic mean and standard deviation of the inputs along the time steps dimension,\n",
    "    then output the concatenation of the computed stats.\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        means = tf.math.reduce_mean(inputs, axis=TIME_AXIS, keepdims=True)\n",
    "        variances = tf.math.reduce_mean(tf.math.square(inputs - means), axis=TIME_AXIS)\n",
    "        means = tf.squeeze(means, TIME_AXIS)\n",
    "        stddevs = tf.math.sqrt(tf.clip_by_value(variances, STDDEV_SQRT_MIN_CLIP, variances.dtype.max))\n",
    "        return tf.concat((means, stddevs), axis=TIME_AXIS)\n",
    "\n",
    "\n",
    "def frame_layer(filters, kernel_size, strides, padding=\"causal\", activation=\"relu\", name=\"frame\"):\n",
    "    return Conv1D(filters, kernel_size, strides, padding=padding, activation=activation, name=name)\n",
    "\n",
    "\n",
    "def segment_layer(units, activation=\"relu\", name=\"segment\"):\n",
    "    return Dense(units, activation=activation, name=name)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    GaussianNoise,\n",
    "    Input,\n",
    "    Layer,\n",
    "    LSTM,\n",
    "    Multiply,\n",
    "    Reshape,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def frequency_attention(H, d_a=64, d_f=16):\n",
    "    assert not H.shape[2] % d_f, \"amount of frequency channels ({}) must be evenly divisible by the amount of frequency attention bins (d_f={})\".format(H.shape[2], d_f)\n",
    "    # Note, we assume that H.shape = (batch_size, T, d_h), but the paper assumes the timesteps come last\n",
    "    x = Dense(d_a, activation=\"relu\", use_bias=False, name=\"Wf_1\")(H)\n",
    "    F_A = Dense(d_f, activation=\"softmax\", use_bias=False, name=\"Wf_2\")(x)\n",
    "    # Apply frequency attention on d_f bins\n",
    "    F_A = Reshape((F_A.shape[1] or -1, F_A.shape[2], 1), name=\"expand_bin_weight_dim\")(F_A)\n",
    "    H_bins = Reshape((H.shape[1] or -1, d_f, H.shape[2] // d_f), name=\"partition_freq_bins\")(H)\n",
    "    H_bins = Multiply(name=\"freq_attention\")([F_A, H_bins])\n",
    "    # Merge weighted frequency bins\n",
    "    H_weighted = Reshape((H.shape[1] or -1, H.shape[2]), name=\"merge_weighted_bins\")(H_bins)\n",
    "    return H_weighted\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Input,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def create(input_shape, num_outputs, output_activation=\"log_softmax\", freq_attention_bins=60):\n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "    x = SpatialDropout1D(0.8, name=\"channel_dropout\")(inputs)\n",
    "\n",
    "    x = frame_layer(512, 5, 1, name=\"frame1\")(x)\n",
    "    x = frame_layer(512, 3, 2, name=\"frame2\")(x)\n",
    "    x = frame_layer(512, 3, 3, name=\"frame3\")(x)\n",
    "    x = frame_layer(512, 1, 1, name=\"frame4\")(x)\n",
    "    x = frame_layer(1500, 1, 1, name=\"frame5\")(x)\n",
    "\n",
    "    x = frequency_attention(x, d_f=freq_attention_bins)\n",
    "\n",
    "    x = GlobalMeanStddevPooling1D(name=\"stats_pooling\")(x)\n",
    "\n",
    "    x = segment_layer(512, name=\"segment1\")(x)\n",
    "    x = segment_layer(512, name=\"segment2\")(x)\n",
    "\n",
    "    outputs = Dense(num_outputs, name=\"output\", activation=None)(x)\n",
    "    if output_activation:\n",
    "        outputs = Activation(getattr(tf.nn, output_activation), name=str(output_activation))(outputs)\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"x-vector-frequency-attention\")\n",
    "\n",
    "\n",
    "\n",
    "def create_model(num_freq_bins=40, num_labels=len(np.unique(meta.target))):\n",
    "    m = create(\n",
    "        input_shape=[None, num_freq_bins],\n",
    "        num_outputs=num_labels)\n",
    "    \"\"\"\n",
    "    m.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "    \"\"\"\n",
    "    return m\n",
    "\n",
    "with tf.device(\"GPU\"):\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    pass\n",
    "\n",
    "model.trainable = False\n",
    "x = model.layers[-3].output \n",
    "x = Dense(256, activation = \"relu\")(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Dense(128, activation = \"relu\")(x)\n",
    "x = Dropout(0.35)(x)\n",
    "predictions = Dense(4, activation = \"softmax\")(x)\n",
    "clf1 = Model(inputs = model.input, outputs = predictions, name=\"clf1\")\n",
    "\n",
    "clf1.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "\n",
    "model.trainable = False\n",
    "x = model.layers[-3].output \n",
    "x = Dense(256, activation = \"relu\")(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Dense(128, activation = \"relu\")(x)\n",
    "x = Dropout(0.35)(x)\n",
    "predictions = Dense(4, activation = \"softmax\")(x)\n",
    "clf2 = Model(inputs = model.input, outputs = predictions, name=\"clf2\")\n",
    "\n",
    "\n",
    "clf2.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np_rng = np.random.default_rng(1)\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "\n",
    "\n",
    "import urllib.parse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "\n",
    "from lidbox.meta import (\n",
    "    common_voice,\n",
    "    generate_label2target,\n",
    "    verify_integrity,\n",
    "    read_audio_durations,\n",
    "    random_oversampling_on_split\n",
    ")\n",
    "\n",
    "tf.random.set_seed(np_rng.integers(0, tf.int64.max))\n",
    "\n",
    "train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"new_test.tsv\", sep=\"\\t\")\n",
    "dev = pd.read_csv(\"new_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "train[\"path\"] = train[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "test[\"path\"] = test[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "dev[\"path\"] = dev[\"path\"].apply(lambda x: x[:-3] + \"mp3\")\n",
    "\n",
    "train[\"split\"] = \"train\"\n",
    "test[\"split\"] = \"test\"\n",
    "dev[\"split\"] = \"dev\"\n",
    "meta = pd.concat([train, test, dev])\n",
    "\n",
    "\n",
    "\n",
    "meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\")))), \"path\"] = \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"locale\"]  + \"/clips/\" + meta.loc[((meta[\"locale\"] != \"kz\") & ~(((meta[\"split\"] == \"dev\") | (meta[\"split\"] == \"test\")) & ((meta[\"locale\"] == \"ru\") | (meta[\"locale\"] == \"kz\") | (meta[\"locale\"] == \"en\"))))][\"path\"]\n",
    "targets = {\"kz\": 0, \"ru\": 1, \"en\":2, \"other\":3}\n",
    "meta[\"target\"] = meta[\"locale\"]\n",
    "meta.loc[(meta[\"locale\"] != \"kz\") & (meta[\"locale\"] != \"ru\") & (meta[\"locale\"]!=\"en\"), \"target\"] = \"other\"\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5f590a130a73c.mp3\"]\n",
    "meta = meta.loc[meta[\"path\"] != \"/tf/datasets/data_untar/cv-corpus-6.1-2020-12-11/kz/clips/5ef9bd9ba7029.mp3\"]\n",
    "\n",
    "meta[\"id\"] = str(meta[\"Unnamed: 0\"])\n",
    "meta[\"target\"] = meta[\"target\"].map(targets)\n",
    "\n",
    "\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_test/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"test\") & (meta[\"locale\"] == \"en\"), \"path\"] \n",
    "\n",
    "\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/ru_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"ru\"), \"path\"]\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/kz_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"kz\"), \"path\"] \n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] = meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\")][\"path\"].apply(lambda x: f\"/tf/datasets/vox/en_dev/{x}\")\n",
    "meta.loc[(meta[\"split\"] == \"dev\") & (meta[\"locale\"] == \"en\"), \"path\"] \n",
    "\n",
    "\n",
    "meta.loc[meta[\"split\"]==\"test\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"test\"][\"path\"]\n",
    "meta.loc[meta[\"split\"]==\"dev\", \"Unnamed: 0\"] = meta.loc[meta[\"split\"]==\"dev\"][\"path\"]\n",
    "\n",
    "\n",
    "meta[\"id\"] = meta[\"Unnamed: 0\"].apply(str)\n",
    "\n",
    "meta.loc[meta[\"split\"] == \"test\", \"id\"] = meta.loc[meta[\"split\"] == \"test\"][\"path\"]\n",
    "\n",
    "\n",
    "meta = meta.set_index(\"Unnamed: 0\")\n",
    "meta.loc[meta[\"split\"]==\"dev\"]\n",
    "\n",
    "meta.loc[meta[\"split\"] == \"test\"] = meta.loc[(meta[\"split\"] == \"test\") & (meta[\"target\"] != 3)] \n",
    "\n",
    "\n",
    "split2ds = {split: pipeline_from_meta(meta[meta[\"split\"]==split], split)\n",
    "            for split in meta.split.unique()}\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "EPOCHS = 100 \n",
    "dev_iterator = iter(split2ds[\"dev\"].batch(32).repeat(1000))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "best_acc = 0\n",
    "counter = 0\n",
    "MAX_PATIENCE = 5\n",
    "\n",
    "\n",
    "def discrepancy(out1, out2):\n",
    "    return tf.reduce_mean(tf.abs(out1 - out2))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"It is epoch number: {epoch}\")\n",
    "    avg_loss = 0\n",
    "    for i in tqdm(split2ds[\"train\"].batch(32)):\n",
    "        \n",
    "        clf1.trainable = True\n",
    "        clf2.trainable = True\n",
    "        model.trainable = True\n",
    "        model.layers[-1].trainable = False\n",
    "        model.layers[-2].trainable = False\n",
    "        target_data = next(dev_iterator)\n",
    "        s_specs = i['logmelspec']\n",
    "        t_specs = target_data['logmelspec']\n",
    "        # Train for classification\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred1 = clf1(s_specs)\n",
    "            pred2 = clf2(s_specs)\n",
    "            loss_classification_1 = loss_fn(i['target'], pred1)\n",
    "            loss_classification_2 = loss_fn(i['target'], pred2)\n",
    "            total_classification_loss = loss_classification_1 + loss_classification_2\n",
    "            avg_loss += total_classification_loss\n",
    "            \n",
    "        train_acc_metric.update_state(i['target'], pred1)\n",
    "        grads = tape.gradient(total_classification_loss, [clf1.trainable_weights, clf2.trainable_weights, model.trainable_weights])\n",
    "        optimizer.apply_gradients(zip(grads[0], clf1.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[1], clf2.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[2], model.trainable_weights))\n",
    "        # Train for discrepancy increase\n",
    "        model.trainable = False\n",
    "        with tf.GradientTape() as tape2:\n",
    "            pred1 = clf1(s_specs)\n",
    "            pred2 = clf2(s_specs)\n",
    "            loss_classification_1 = loss_fn(i['target'], pred1)\n",
    "            loss_classification_2 = loss_fn(i['target'], pred2)\n",
    "            total_classification_loss = loss_classification_1 + loss_classification_2\n",
    "            pred1 = clf1(t_specs)\n",
    "            pred2 = clf2(t_specs)\n",
    "            discrepancy_loss = discrepancy(pred1, pred2)\n",
    "            loss = total_classification_loss - discrepancy_loss\n",
    "        grads = tape2.gradient(loss, [clf1.trainable_weights, clf2.trainable_weights])\n",
    "        optimizer.apply_gradients(zip(grads[0], clf1.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(grads[1], clf2.trainable_weights))\n",
    "        # Train for discrepancy decrease\n",
    "        clf1.trainable = False\n",
    "        clf2.trainable = False\n",
    "        model.trainable = True\n",
    "        model.layers[-1].trainable = False\n",
    "        model.layers[-2].trainable = False\n",
    "        dloss = 0\n",
    "        for k in range(3):\n",
    "            with tf.GradientTape() as tape3:\n",
    "                pred1 = clf1(t_specs)\n",
    "                pred2 = clf2(t_specs)\n",
    "                discrepancy_loss = discrepancy(pred1, pred2)\n",
    "                dloss = discrepancy_loss\n",
    "            grads = tape3.gradient(discrepancy_loss, model.trainable_weights)\n",
    "            optimizer2.apply_gradients(zip(grads, clf1.trainable_weights))\n",
    "    print(dloss)\n",
    "    for batch in tqdm(val_data.batch(32)):\n",
    "        val_preds = clf1(batch['logmelspec'])\n",
    "        true_vals = batch['target']  \n",
    "        val_acc_metric.update_state(true_vals, val_preds)\n",
    "    new_acc = 0\n",
    "    val_acc = val_acc_metric.result()\n",
    "    new_acc += val_acc\n",
    "    val_acc_metric.reset_states()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    print(f\"Val acc: {val_acc}, Train acc: {train_acc}. Train loss (clf1): {avg_loss/9783}\")\n",
    "    for batch in tqdm(val_data.batch(32)):\n",
    "        val_preds = clf2(batch['logmelspec'])\n",
    "        true_vals = batch['target']  \n",
    "        val_acc_metric.update_state(true_vals, val_preds)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_acc_metric.reset_states()\n",
    "    print(f\"Val acc (clf2): {val_acc}.\")\n",
    "    new_acc += val_acc\n",
    "    if new_acc / 2 > best_acc:\n",
    "        print(f\"Here is an improvement from {best_acc} to {new_acc / 2}\\nSaving results\")\n",
    "        best_acc = new_acc / 2\n",
    "        counter = 0\n",
    "        clf1.save(\"clf1_3/model\")\n",
    "        clf2.save(\"clf2_3/model\")\n",
    "        model.save(\"extractor/model\")\n",
    "    else:\n",
    "        print(\"No improvements\")\n",
    "        counter += 1\n",
    "    if counter >= MAX_PATIENCE:\n",
    "        break\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff13c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 27 09:02:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.116.00   Driver Version: 418.116.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:59:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    67W / 350W |  31928MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3a4fd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_5/kernel:0' shape=(128, 4) dtype=float32, numpy=\n",
       " array([[ 0.06229074, -0.04258064, -0.11776436,  0.0842173 ],\n",
       "        [ 0.13196267,  0.10288537, -0.17594309, -0.20202594],\n",
       "        [ 0.15362234, -0.06542542,  0.16923791,  0.11284675],\n",
       "        [ 0.10355131, -0.03872748, -0.06280154, -0.04122264],\n",
       "        [-0.18054143, -0.07805274,  0.05123596,  0.16314806],\n",
       "        [ 0.06057722,  0.05792367, -0.11219296, -0.12105943],\n",
       "        [ 0.17948827,  0.18962532,  0.0896791 ,  0.09131058],\n",
       "        [-0.02762377, -0.11449677, -0.14906867,  0.20326547],\n",
       "        [ 0.14770162,  0.14940903,  0.06833924, -0.03595854],\n",
       "        [ 0.2071131 ,  0.16579787, -0.14281693,  0.11614902],\n",
       "        [ 0.10809997, -0.18665992,  0.15859091,  0.09405592],\n",
       "        [-0.20482661, -0.05323299, -0.04854409, -0.1432973 ],\n",
       "        [ 0.0270332 ,  0.1708592 ,  0.1535456 ,  0.170187  ],\n",
       "        [-0.19907099, -0.09916333, -0.10690525,  0.16883467],\n",
       "        [-0.17910182,  0.00298523,  0.0787999 , -0.03236267],\n",
       "        [ 0.10683445,  0.026998  , -0.1715097 , -0.05866208],\n",
       "        [ 0.03173674, -0.18919536,  0.04874013,  0.17604113],\n",
       "        [-0.18150143, -0.0257847 , -0.14347287, -0.12641285],\n",
       "        [-0.18778577, -0.17840691, -0.20536628, -0.15660322],\n",
       "        [ 0.02244931,  0.17501487,  0.00534029,  0.05353687],\n",
       "        [-0.06409371,  0.08536472, -0.14318758,  0.16757584],\n",
       "        [ 0.09298158, -0.17509684, -0.1803496 ,  0.19872738],\n",
       "        [-0.0944604 , -0.1601973 , -0.05955807, -0.15385813],\n",
       "        [ 0.02696774, -0.06926391, -0.04684141, -0.1747361 ],\n",
       "        [-0.02172116,  0.18836263, -0.06478023, -0.21601377],\n",
       "        [ 0.03100979,  0.1462586 ,  0.18263821,  0.01765163],\n",
       "        [ 0.0604473 ,  0.12840568,  0.16855507,  0.00587106],\n",
       "        [-0.2100964 ,  0.06789178, -0.08706606,  0.06456073],\n",
       "        [-0.11263947,  0.04814861,  0.11592928, -0.12619817],\n",
       "        [-0.15886527, -0.12380042,  0.15787691,  0.18986331],\n",
       "        [-0.10425874, -0.04570382,  0.16762173, -0.02061538],\n",
       "        [-0.15692389,  0.08793375,  0.12369027,  0.00024504],\n",
       "        [ 0.09511287, -0.15806167,  0.17606987,  0.1859567 ],\n",
       "        [ 0.09520555,  0.19495182,  0.09051019,  0.12248117],\n",
       "        [ 0.01056742,  0.0651262 , -0.03081976, -0.00777384],\n",
       "        [ 0.09892251,  0.19070154,  0.06135222,  0.06535542],\n",
       "        [ 0.01651045,  0.11839845,  0.0145562 , -0.16231635],\n",
       "        [-0.00599212, -0.04675209,  0.14293453, -0.00919433],\n",
       "        [ 0.01975434,  0.10634332,  0.16017315,  0.02979545],\n",
       "        [ 0.06299071,  0.17811286, -0.14449754,  0.19524704],\n",
       "        [-0.06420638, -0.12750204,  0.12734558, -0.06949516],\n",
       "        [-0.04175789,  0.004261  ,  0.18613817,  0.20142655],\n",
       "        [-0.07287625,  0.10438909, -0.00026303, -0.20263639],\n",
       "        [ 0.15713513,  0.02698922,  0.13363035, -0.13347644],\n",
       "        [-0.18174824,  0.20071235,  0.12696226, -0.08518033],\n",
       "        [-0.02578859,  0.09377226, -0.19780824, -0.1853266 ],\n",
       "        [-0.05457757, -0.07607754, -0.10314818, -0.03529956],\n",
       "        [ 0.15181166,  0.00428811,  0.01887516,  0.02990117],\n",
       "        [-0.1623917 , -0.06417409, -0.05807316, -0.02486115],\n",
       "        [-0.19129907,  0.0861425 ,  0.08471807, -0.09125432],\n",
       "        [ 0.02034527, -0.03767052, -0.09706911,  0.05933247],\n",
       "        [ 0.16749051,  0.17996836,  0.1998034 ,  0.09662412],\n",
       "        [-0.0703527 ,  0.2059097 , -0.08362292, -0.16812141],\n",
       "        [-0.17246328, -0.19482975,  0.06191125,  0.01743549],\n",
       "        [ 0.13176271, -0.14764208, -0.0652052 ,  0.16101573],\n",
       "        [-0.14386506,  0.03481681,  0.16206306, -0.15163046],\n",
       "        [-0.07457388, -0.14081013, -0.10025765, -0.09382609],\n",
       "        [ 0.13973147,  0.15194337,  0.01092432,  0.17059022],\n",
       "        [ 0.08250702, -0.19025517,  0.14553006, -0.1010178 ],\n",
       "        [ 0.1872741 ,  0.08732428, -0.00037268, -0.10371   ],\n",
       "        [ 0.11134093, -0.03466418,  0.18721631, -0.06708806],\n",
       "        [-0.08898114,  0.132805  ,  0.00237042, -0.09458888],\n",
       "        [ 0.06970856,  0.13751657,  0.21572597, -0.03932887],\n",
       "        [-0.00330429,  0.12400509, -0.0878282 , -0.14086898],\n",
       "        [ 0.05125397, -0.10971104,  0.18047458, -0.02483924],\n",
       "        [ 0.12286991,  0.00520822, -0.00321669,  0.18026434],\n",
       "        [ 0.09293102, -0.07417526, -0.16167049,  0.00680236],\n",
       "        [-0.05616899,  0.08987777, -0.13995402,  0.17387682],\n",
       "        [ 0.15764846,  0.06333271, -0.10522874,  0.07577091],\n",
       "        [ 0.2313175 ,  0.18703358,  0.09021083, -0.11416794],\n",
       "        [ 0.02892176,  0.01414416, -0.08675722,  0.19644333],\n",
       "        [-0.06833745, -0.03750767,  0.04833995,  0.05923259],\n",
       "        [-0.09552315,  0.13269366, -0.18781126, -0.15600389],\n",
       "        [ 0.04416526, -0.14596821,  0.14197935,  0.16408572],\n",
       "        [ 0.05171624, -0.04406847, -0.18401858, -0.15877935],\n",
       "        [ 0.05300773,  0.14726943,  0.06534053,  0.11618334],\n",
       "        [ 0.10204714,  0.00863557, -0.13171004, -0.03149695],\n",
       "        [ 0.01720134,  0.08909926, -0.04897881, -0.06319439],\n",
       "        [ 0.09925324,  0.01607505, -0.01907075,  0.05060713],\n",
       "        [ 0.03915784,  0.04527057,  0.07969829, -0.0368279 ],\n",
       "        [ 0.02224915, -0.07367673, -0.0682625 ,  0.06740031],\n",
       "        [ 0.12324493, -0.03344801, -0.08814814, -0.06104885],\n",
       "        [ 0.14752287, -0.15417017,  0.08091763, -0.06260327],\n",
       "        [-0.07530788, -0.19321026, -0.167943  ,  0.11717609],\n",
       "        [-0.1490096 ,  0.10913247,  0.1010388 ,  0.12708019],\n",
       "        [-0.06649907, -0.09900649, -0.01638561,  0.04787434],\n",
       "        [ 0.04810579,  0.1430419 ,  0.0076176 ,  0.08240331],\n",
       "        [-0.15689467,  0.10072137,  0.04609382, -0.169303  ],\n",
       "        [ 0.11740833, -0.17419754,  0.09421972,  0.07113745],\n",
       "        [ 0.01119531,  0.07364572, -0.05086435,  0.15385507],\n",
       "        [ 0.16085856,  0.1143316 , -0.14522079, -0.07587215],\n",
       "        [-0.15031908, -0.1612052 ,  0.06113688,  0.11715198],\n",
       "        [-0.02317829,  0.19278477,  0.18265408,  0.20324895],\n",
       "        [ 0.12453344, -0.11974515, -0.13998702,  0.08545016],\n",
       "        [-0.05437513,  0.08777606, -0.033285  , -0.10311618],\n",
       "        [ 0.01670543, -0.12272479,  0.02534157,  0.01791458],\n",
       "        [-0.0770634 ,  0.19056618,  0.03211313,  0.16584685],\n",
       "        [-0.04170087,  0.03598445,  0.12697063,  0.20866303],\n",
       "        [-0.11953952,  0.17741904, -0.04840041, -0.06887922],\n",
       "        [-0.16710825,  0.11377587,  0.05984516, -0.08687685],\n",
       "        [ 0.06049222,  0.1907428 ,  0.00496488, -0.04671554],\n",
       "        [-0.19282319, -0.07557774, -0.07598497, -0.17819358],\n",
       "        [-0.01101393,  0.09312031, -0.13196677,  0.06456389],\n",
       "        [-0.11955586, -0.15624863,  0.06264336, -0.19452727],\n",
       "        [ 0.12436707,  0.17899875,  0.00549263, -0.07108524],\n",
       "        [-0.0366399 ,  0.02821012, -0.01093875,  0.0293293 ],\n",
       "        [ 0.052269  , -0.02218359,  0.12490248,  0.03197993],\n",
       "        [ 0.00811573, -0.01371988, -0.1681174 , -0.05127864],\n",
       "        [ 0.05279758, -0.15989336, -0.12611273, -0.11184463],\n",
       "        [-0.07541181,  0.00733694, -0.01352424,  0.03207395],\n",
       "        [-0.05681016, -0.19185382,  0.18385446, -0.1303603 ],\n",
       "        [ 0.14126694, -0.03514925,  0.1153502 ,  0.1551336 ],\n",
       "        [-0.04412537,  0.15661465, -0.09240879,  0.12394365],\n",
       "        [ 0.22808075,  0.05695781, -0.09728759, -0.06013738],\n",
       "        [-0.00457551,  0.05089293, -0.11876182, -0.12799293],\n",
       "        [-0.21329984,  0.17907752,  0.04193025, -0.0174883 ],\n",
       "        [-0.1851722 ,  0.10809599, -0.08156979,  0.00191671],\n",
       "        [-0.11645439,  0.14037733, -0.01066701, -0.00787652],\n",
       "        [-0.07455911, -0.03592116,  0.14929478,  0.0751853 ],\n",
       "        [ 0.07630073, -0.10655954, -0.16104543, -0.02271482],\n",
       "        [ 0.0448984 ,  0.13784978, -0.13457431, -0.13779493],\n",
       "        [-0.15958582, -0.1720953 , -0.00046376, -0.14414373],\n",
       "        [-0.0710358 ,  0.11850653, -0.10385041, -0.12544455],\n",
       "        [-0.01565298,  0.15382828, -0.14685644, -0.07877808],\n",
       "        [-0.02971665, -0.12261156,  0.1258789 ,  0.04346308],\n",
       "        [ 0.04865681,  0.03256776,  0.04083204, -0.05071846],\n",
       "        [ 0.07723314,  0.0203131 ,  0.05983143, -0.15105242],\n",
       "        [ 0.13493703, -0.2034522 , -0.11700147,  0.04540508]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(4,) dtype=float32, numpy=array([ 0.16443267, -0.0610443 , -0.0931678 , -0.09415696], dtype=float32)>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.layers[-1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f4471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
